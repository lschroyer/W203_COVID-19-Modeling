---
title: "Model 2 clean_script"
author: "Jun Qian, Lucas Schroyer, Ryan Mitchell, Oliver Chang"
date: "4/8/2021"
output: 
  html_document: default
  pdf_document: default

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r load packages, echo=FALSE, warning=FALSE, message=FALSE}
rm(list = ls())
library(dplyr)
library(ggplot2) 
library(purrr)
library(haven)
library(tidyverse)
# install.packages("DescTools")
library(DescTools)
library(magrittr)
library(kableExtra)
require(plotrix)
# install.packages("magick")
# install.packages("webshot")
library("magick")
library("webshot")
webshot::install_phantomjs()

#install.packages("openxlsx") 
library(openxlsx)
#install.packages("readxl")
library(readxl)
#nstall.packages("rapportools")
library(rapportools)
#install.packages("data.table")
library(data.table)

library(patchwork)
library(sandwich)
library(lmtest)

#install.packages("corrplot")
#install.packages("psych")
library(corrplot)
library(psych)
library(stargazer)
```


```{r read in model 1 outputs}
load("pwd/model_1_workspace.RData")
```

# Second Model. 

As we thought about an approach to building our Model 2 specifications, the general approach that our group decided to take was to incrementally test the addition of new features to our Model 1 specification in descending order of expected importance, according to our general understanding of how viruses spread. At each iteration, we began by examining the relationship (using scatterplots) between a new demographic or policy-related feature and our outcome of interest: COVID cases per 100K people 365 days after each state declared a state of emergency. If we observed a relationship, we ran a combination of t-Tests and/or ANOVA F-Tests to determine whether or not to add the feature to our Model 1 specification. We proceeded in this 'greedy' algorithmic fashion by adding variables to our Model 1 specification until we could no longer justify further additions based on results from ANOVA F-Tests. The first incremental feature we tested was derived from observational data from the census bureau on population age distributions by state. 

One of the contributing factors to the spread of COVID-19 is asymptomatic spread. Younger people have been shown to have milder symptoms and therefore it stands to reason that they may be less likely to get tested, and ultimately end up spreading the disease at a greater rate than older age groups. To make matters worse, younger people tend to interact with more people (source?) as a result of being in school (switching between classrooms, touching desks and other surfaces where other students have been, congregating in large cafeterias, etc.), which increases the probability of viral transmission. Hence, for our second model, we were interested in testing our general hypothesis that age demographics may play a role in the spread of COVID-19. We began by doing some basic exploratory data analysis (EDA) with respect to age distributions and cumulative COVID-19 case counts per 100K, which is our target variable for Lab 2.

```{r age EDA < 24, echo=FALSE, message=FALSE}
census_df<-final_df[c('cases_per_100k_at_365d', 
                      'Percent.Sex.And.Age.Total.Population.Under.5.Years', 
                      'Percent.Sex.And.Age.Total.Population.5.To.9.Years', 
                      'Percent.Sex.And.Age.Total.Population.10.To.14.Years', 
                      'Percent.Sex.And.Age.Total.Population.15.To.19.Years',
                      'Percent.Sex.And.Age.Total.Population.20.To.24.Years')]

names(census_df) <- names(census_df) %>% gsub(pattern = "Percent.Sex.And.Age.Total.Population.", replacement = "Pct. ") %>%  
  gsub(pattern = ".To.", replacement = "- \n") %>%  
  gsub(pattern = ".Years", replacement = " Yrs") %>%  
  gsub(pattern = 'cases_per_100k_at_365d', 
       replacement = " Cases per \n 100k")

panel.hist <- function(x, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(usr[1:2], 0, 1.5) )
    h <- hist(x, plot = FALSE)
    breaks <- h$breaks; nB <- length(breaks)
    y <- h$counts; y <- y/max(y)
    rect(breaks[-nB], 0, breaks[-1], y, col = "cyan", ...)
}

panel.cor<-function(x,y)
  {
    usr<-par("usr"); on.exit(par(usr))
    par(usr=c(0,1,0,1))
    r=round(cor(x,y),digits=2)
    text(0.5,0.5,r)
  }

census_df %>% names()
pairs(census_df,lower.panel = panel.cor,
      upper.panel = panel.smooth, 
      diag.panel = panel.hist, 
      cex.labels=1, 
      gap = 0.5,
      labels = c("Cases", "%<5", "% 5-9", "%10-14", "%15-19", "%20-24"),
      main = "")




```


```{r age EDA 25-59, echo=FALSE, message=FALSE}
census_df<-final_df[c('cases_per_100k_at_365d', 'Percent.Sex.And.Age.Total.Population.25.To.34.Years','Percent.Sex.And.Age.Total.Population.35.To.44.Years','Percent.Sex.And.Age.Total.Population.45.To.54.Years', 'Percent.Sex.And.Age.Total.Population.55.To.59.Years')]

names(census_df) <- names(census_df) %>% gsub(pattern = "Percent.Sex.And.Age.Total.Population.", replacement = "Pct. ") %>%  gsub(pattern = ".To.", replacement = "- \n") %>%  gsub(pattern = ".Years", replacement = " Yrs") %>%  gsub(pattern = 'cases_per_100k_at_365d', replacement = " Cases per \n 100k")

panel.cor<-function(x,y)
  {
    usr<-par("usr"); on.exit(par(usr))
    par(usr=c(0,1,0,1))
    r=round(cor(x,y),digits=2)
    text(0.5,0.5,r)
  }

pairs(census_df,lower.panel = panel.cor,upper.panel = panel.smooth, diag.panel = panel.hist, cex.labels=1)
```

```{r age EDA 60+, echo=FALSE, message=FALSE}
census_df<-final_df[c('cases_per_100k_at_365d','Percent.Sex.And.Age.Total.Population.60.To.64.Years','Percent.Sex.And.Age.Total.Population.65.To.74.Years', 'Percent.Sex.And.Age.Total.Population.75.To.84.Years', 'Percent.Sex.And.Age.Total.Population.85.Years.And.Over')]

names(census_df) <- names(census_df) %>% gsub(pattern = "Percent.Sex.And.Age.Total.Population.", replacement = "Pct. ") %>%  gsub(pattern = ".To.", replacement = "- \n") %>%  gsub(pattern = ".Years", replacement = " Yrs") %>%  gsub(pattern = 'cases_per_100k_at_365d', replacement = " Cases per \n 100k")

panel.cor<-function(x,y)
  {
    usr<-par("usr"); on.exit(par(usr))
    par(usr=c(0,1,0,1))
    r=round(cor(x,y),digits=2)
    text(0.5,0.5,r)
  }

pairs(census_df,lower.panel = panel.cor,upper.panel = panel.smooth, diag.panel = panel.hist, cex.labels=1)
```


```{r age demo F-tests for feature creation, echo=FALSE, message=FALSE}

#Build nested models for categorical age demographic data where visual inspection suggested interesting relationships with target
model_a = lm(cases_per_100k_at_365d ~ median_transit_change + Percent.Sex.And.Age.Total.Population.Under.5.Years, data = final_df)

model_b = lm(cases_per_100k_at_365d ~ median_transit_change + Percent.Sex.And.Age.Total.Population.Under.5.Years + Percent.Sex.And.Age.Total.Population.5.To.9.Years, data = final_df)

model_c = lm(cases_per_100k_at_365d ~ median_transit_change + Percent.Sex.And.Age.Total.Population.Under.5.Years + Percent.Sex.And.Age.Total.Population.5.To.9.Years + Percent.Sex.And.Age.Total.Population.10.To.14.Years, data = final_df)

model_d = lm(cases_per_100k_at_365d ~ median_transit_change + Percent.Sex.And.Age.Total.Population.Under.5.Years + Percent.Sex.And.Age.Total.Population.5.To.9.Years + Percent.Sex.And.Age.Total.Population.10.To.14.Years + Percent.Sex.And.Age.Total.Population.15.To.19.Years, data = final_df)

model_e = lm(cases_per_100k_at_365d ~ median_transit_change + Percent.Sex.And.Age.Total.Population.Under.5.Years + Percent.Sex.And.Age.Total.Population.5.To.9.Years + Percent.Sex.And.Age.Total.Population.10.To.14.Years + Percent.Sex.And.Age.Total.Population.15.To.19.Years + Percent.Sex.And.Age.Total.Population.20.To.24.Years, data = final_df)


#Significant 
anova(model_a, model_1_final, test = "F")

#Insignificant 
anova(model_b, model_a, test = "F")

#Significant F-test
anova(model_c, model_a, test = "F")

#Insignificant relative to model_c
anova(model_d, model_c, test = "F")
anova(model_e, model_d, test = "F")
anova(model_e, model_c, test = "F")
```

When performing EDA on the categorical age group distributions and their relationship to our target variable, we noticed a strong positive correlation to the target among age groups 0-24. Age groups in the 24+ range did not appear to follow a consistent pattern with respect to correlation with our target variable and were therefore not a key focus area for our analysis.

Next, we performed a series of ANOVA F-tests on a nested set of linear regression models with parameter estimates for this set of age groups (Under 5, 5-9, 10-14, 15-19, and 20-24) as well as our main variable of interest (median transit mobility change). Our motivation here was to understand whether the regression residuals were measurably different from one another between the different (nested) model specifications. For context, the null hypothesis for an F-test is that fitting additional coefficients for a longer model does not measurably reduce the residuals relative to a nested model with fewer parameters. 

Our first ANOVA F-test compared our Model 1 with a new model that had an additional parameter estimate for the percentage of the population under 5 years old. With a p-value of 0.0003, we rejected the null hypothesis and used this new model (model_a) as the baseline model for subsequent comparisons with additional parameter estimates for different age categories. 

We failed to reject the null hypothesis when adding an estimator for ages 5-9 (model_b), and succeeded in rejecting the null hypothesis when adding an estimator for ages 10-14 (model_c), with a p-value of 0.001. Adding additional estimators for 15-19 and 20-24 failed to reject the null hypothesis that these models (model_d and model_e) were measurably better at reducing residuals than model_c. These results suggested creating two new features for the percentage of the population ages 0-9 and 10-24 and adding them to our base Model 1 to create the first specification for our Model 2.

```{r df update 1, echo=FALSE, message=FALSE} 
final_df <- final_df %>% mutate(pop_pct_age_0_9 = Percent.Sex.And.Age.Total.Population.Under.5.Years + Percent.Sex.And.Age.Total.Population.5.To.9.Years,
                    pop_pct_age_10_24 = Percent.Sex.And.Age.Total.Population.10.To.14.Years + Percent.Sex.And.Age.Total.Population.15.To.19.Years + Percent.Sex.And.Age.Total.Population.20.To.24.Years)

cor(final_df$pop_pct_age_0_9, final_df$pop_pct_age_10_24)

final_df <- final_df %>% mutate(pop_pct_age_0_24 = Percent.Sex.And.Age.Total.Population.Under.5.Years + Percent.Sex.And.Age.Total.Population.5.To.9.Years + Percent.Sex.And.Age.Total.Population.10.To.14.Years + Percent.Sex.And.Age.Total.Population.15.To.19.Years + Percent.Sex.And.Age.Total.Population.20.To.24.Years)
```

However, after measuring a 0.77 correlation between these two features - and with the goal of increased model parsimony - we decided to group them together to prevent the standard errors for their respective coefficients from increasing substantially. Let's take a look and assess whether this new variable for percentage of the population < 24 years old visually satisfies the conditional linearity expectation with respect to our target.

```{r incremental variables 1, echo=FALSE, message=FALSE}
ggplot(data = final_df) +
  geom_point(aes(x = pop_pct_age_0_24,
                 y = cases_per_100k_at_365d)) +
  geom_smooth(aes(x = pop_pct_age_0_24,
                 y = cases_per_100k_at_365d),
            colour = 'red',
            method = 'lm', se = FALSE) +
  geom_smooth(aes(x = pop_pct_age_0_24,
                  y = cases_per_100k_at_365d),
            colour = 'blue',
            method = 'loess', se = TRUE) +
  labs(title = 'Percentage of State Population Under Age 25 vs. \nCases Per 100K People at One Year After SOE',
       x='Percentage of State Population Under Age 25',
       y='Cases Per 100K People One Year After SOE') +
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=12))
```

The conditional linear expectation between our population percentage aged 0-24 and our target appears to be met. In addition to evaluating the linear relationships between the demographic age variables and our target, we also evaluated the log, square root, and square transformations to the age distribution data but did not find them to aid in reducing the frequency or magnitude of outlier data points. 

Indeed, including a feature for the percentage of the population aged < 24 years old appears to have improved our model's performance. An ANOVA F-test returned a p-value of 0.0001, suggesting that we reject the null hypothesis that the (interim) Model 2's residuals were not measurably different from the residuals of Model 1.

```{r model 2 - part 1, echo=FALSE, message=FALSE}
model_2a <- lm(cases_per_100k_at_365d ~ median_transit_change + pop_pct_age_0_24, data = final_df)
# Significant
anova(model_2a, model_1_final, test = "F")
```

After accounting for changes in mobility and demographic age differences between states, the next variable we wanted to explore as part of our descriptive model for COVID case counts was population density. According to the World Health Organization, "COVID-19 virus is primarily transmitted between people through respiratory droplets and contact routes." (https://www.who.int/news-room/commentaries/detail/modes-of-transmission-of-virus-causing-covid-19-implications-for-ipc-precaution-recommendations). In other words, COVID spreads primarily through physical interactions between infected and uninfected hosts, regardless of whether the actual mechanism of transmission is airborne or surface based contact. Hence, it stands to reason that more densely populated areas would see greater rates of infections, because the frequency of these physical interactions will increase with population density. This was the motivation for our group exploring whether a relationship existed between state population density and our outcome variable of interest.


```{r incremental variables 2, echo=FALSE, message=FALSE}
ggplot(data = final_df) +
  geom_point(aes(x = population_density,
                 y = cases_per_100k_at_365d)) +
  geom_smooth(aes(x = population_density,
                 y = cases_per_100k_at_365d),
            colour = 'red',
            method = 'lm', se = FALSE) +
  geom_smooth(aes(x = population_density,
                  y = cases_per_100k_at_365d),
            colour = 'blue',
            method = 'loess', se = TRUE) +
  labs(title = 'Population Density vs. \nCases Per 100K People at One Year After SOE',
       x='Population Density (people/sq. mi)',
       y='Cases Per 100K People One Year After SOE') +
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=12))
```

To our surprise, however, there was no clear relationship between population density and our outcome variable. A t-Test on the parameter estimate for population density's relationship with our target variable failed to reject the null hypothesis that the coefficient value was not measurably different from zero. 

```{r simple population density model, echo=FALSE, message=FALSE}
model_density <- lm(cases_per_100k_at_365d ~ population_density , data = final_df)
summary(model_density)
```

In spite of this test, our group decided to move forward and try including the population density feature in Model 2, as we believed it to be a conceptually meaningful variable in describing the population prevalence of COVID in each state one year after each state declared a state of emergency. Therefore, we proceeded with an ANOVA F-Test to test whether the incremental population density feature measurably improved model performance (via reduction of residuals) relative to our current model with features for median transit mobility change and percentage of the population < 24 years old. This ANOVA F-test returned a p-value of 0.002, enough to reject the null hypothesis that the model residuals were not measurably different from one another.


```{r model 2 - part 2, echo=FALSE, message=FALSE}
model_2_final <- lm(cases_per_100k_at_365d ~ median_transit_change + pop_pct_age_0_24 + population_density, data = final_df)

cat("\n-------Model results-------\n")
summary(model_2_final)
cat("\n")

# Significance Test Relative To Model 1
cat("\n-------ANOVA F-Test Significance Test Relative To Model 1-------\n")
anova(model_2_final, model_1_final, test = "F")
cat("\n")

# Significance Test Relative To Interim Model 2
cat("\n-------ANOVA F-Test Significance Test Relative To Interim Model 2-------\n")
anova(model_2_final, model_2a, test = "F")
cat("\n")

#-------Model Residual Plot-------
qplot(model_2_final$residuals,
               geom = "histogram", bins = 20) +
         labs(title = "Histogram of Model 2 Residuals",
              x = "residual")

qplot(model_2_final$fitted, model_2_final$residuals,
            geom = "point") +
         geom_abline(intercept = 0,
                     slope = 0,
                     colour = "red") + 
         geom_smooth(aes(x = model_2_final$fitted,
                         y = model_2_final$residuals),
            colour = 'blue',
            method = "loess", se = TRUE) +
         labs(title = "Plot of Residuals vs Fitted Values",
              x = "fitted value",
              y = "residual")


cat("\n-------Homoskedasticity Test-------\n")
lmtest::bptest(model_2_final)
cat("\n")


cat("\n------Normality of Residuals Test-------\n")
shapiro.test(model_2_final$residuals)
cat("\n")
```

Because the population density feature only becomes statistically significant at the p = 0.05 level in our model when we include features for median change in transit mobility and the percentage of the population under age 25, we say that the population density has a conditional relationship with our outcome of interest. Both of these two co-variates (median transit mobility change and percentage of the population under age 25) are negatively correlated with population density and positively correlated with our outcome variable. 

```{r conditional effect population density, echo=FALSE, message=FALSE}
ggplot(data = final_df) +
  geom_point(aes(y = population_density,
                 x = median_transit_change)) +
  geom_smooth(aes(y = population_density,
                 x = median_transit_change),
            colour = 'red',
            method = 'lm', se = FALSE) +
  geom_smooth(aes(y = population_density,
                  x = median_transit_change),
            colour = 'blue',
            method = 'loess', se = TRUE) +
  labs(title = 'Population Density vs. \nMedian Transit Mobility Change',
       y='State Population Density (people/sq. mi)',
       x='State-Level One Year Median Transit Mobility Change') +
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=12))


ggplot(data = final_df) +
  geom_point(aes(y = population_density,
                 x = pop_pct_age_0_24)) +
  geom_smooth(aes(y = population_density,
                 x = pop_pct_age_0_24),
            colour = 'red',
            method = 'lm', se = FALSE) +
  geom_smooth(aes(y = population_density,
                  x = pop_pct_age_0_24),
            colour = 'blue',
            method = 'loess', se = TRUE) +
  labs(title = 'Population Density vs. \nPercent of Population Under Age 25',
       y='State Population Density (people/sq. mi)',
       x='Percentage of the State Population Under Age 25') +
  theme(axis.text=element_text(size=10),
        axis.title=element_text(size=12))

```

However, we are only interested in the unique variation of population density with respect to our outcome variable. When the OLS regression algorithm calculates the parameter estimate for population density, it starts by regressing population density on the other model co-variate (input) features. The residuals from that regression represent the portion of population density that is *not* colinear with median transit mobility change and percentage of the population under age 25. Then OLS regresses our target values on those residuals to derive an estimate for the population density parameter. The model summary tells us that if we hold the percentage of the population under 25 and the median transit mobility change for a state constant (we do not allow them to co-vary), that there exists a positive correlation between population density and our outcome variable at a statistically significant level (p = 0.002) using classical standard errors.

At this stage, we wanted to explore whether any state policy changes aimed at reducing the spread of COVID-19 added incremental descriptive power beyond our current Model 2 specification. In particular, we wanted to examine whether the timing of mask mandates, length and amount of increased government assistance via enhanced unemployment benefits, business closures, stay at home mandates, and travel quarantine restrictions had measurable effects on our outcome of interest after accounting for the features already in our Model 2 specification (which included state-level features for median change in transit mobility, percentage of the population under 25 years of age, and population density). All the policy-related features were recorded as dates, except for the increased unemployment insurance amount, which was recorded as an integer. 

To align with our target variable of COVID-19 Cases per 100K one year after state of emergency declaration, we encoded the date related policy variables as the total number of days each policy was in place for after the state of emergency was announced for each state (up to 365 days). For transparency:

1. If a policy had no beginning and end dates, the total days were assigned as zero.
2. If a policy had beginning but not end dates, the total days were calculated by the date of state emergency declared + 364 days - the date of the beginning of the policy.
3. If a policy had both beginning and end dates, the total days were calculated by the difference in days of the two dates.

Once the policy-related features of our interest were transformed into days in force, we conducted EDA on the policy-features and COVID cases per 100k population using scatter plot and correlation matrices. 

```{r policy days vs cases per capita, echo=FALSE, message=FALSE}

# Plot first half of policy vars
m1 <- select(final_df, cases_per_100k_at_365d, 
             mask_mandate_days,
             unemployment_benefits_days,
             increased_weekly_unemployment_insurance_amt_thru_jul31
            )

panel.cor<-function(x,y)
  {
    usr<-par("usr"); on.exit(par(usr))
    par(usr=c(0,1,0,1))
    r=round(cor(x,y),digits=2)
    text(0.5,0.5,r)
  }

pairs(m1,lower.panel = panel.cor,upper.panel = panel.smooth, diag.panel = panel.hist, cex.labels=1)
m1 %>% names()
pairs(m1,
      gap = 0.5,
      lower.panel = panel.cor,
      upper.panel = panel.smooth,
      labels = c("cases", "transit","0-24", "pop_dens", "mask",
                 "unemployment", "insurance",
                 "open\nclose", "travel\nquarantine", "stay at\nhome"),
      main = "policy days vs cases per capita")


# Plot second half of policy vars
m2 <- select(final_df, cases_per_100k_at_365d, 
             business_closed_days_round1,
             travel_quarantine_mandate_days,
             stay_at_home_days
            )

panel.cor<-function(x,y)
  {
    usr<-par("usr"); on.exit(par(usr))
    par(usr=c(0,1,0,1))
    r=round(cor(x,y),digits=2)
    text(0.5,0.5,r)
  }

pairs(m2,lower.panel = panel.cor,upper.panel = panel.smooth, diag.panel = panel.hist, cex.labels=1)

```
```{r policy correlation plot, echo=FALSE, message=FALSE}
z <- data.frame(final_df$cases_per_100k_at_365d, 
             final_df$mask_mandate_days,
             final_df$unemployment_benefits_days,
             final_df$increased_weekly_unemployment_insurance_amt_thru_jul31,
             final_df$business_closed_days_round1,
             final_df$travel_quarantine_mandate_days,
             final_df$stay_at_home_days) %>%
  dplyr::rename(cases_per_100k = final_df.cases_per_100k_at_365d, 
             mask_days = final_df.mask_mandate_days,
             ue_ben_days = final_df.unemployment_benefits_days,
             ue_ins_amt = final_df.increased_weekly_unemployment_insurance_amt_thru_jul31,
             biz_closed_days = final_df.business_closed_days_round1,
             quarantine_days = final_df.travel_quarantine_mandate_days,
             stay_at_home_days = final_df.stay_at_home_days)

#Visualize the correlation between state policies and cases
M <- cor(z)
mat1 <- data.matrix(M)
print(M)
corrplot(mat1, method = "color", tl.col = 'black', is.corr=FALSE, title = 'Correlation Matrix: State Policies vs. Cases', addCoefasPercent = TRUE,  addCoef.col = "white")
```

From the scatterplots, we see varying degrees of linearity between the policy features and our outcome of interest. We tested each of these features iteratively in the same manner as before, using significance from ANOVA F-tests as the benchmark to decide whether or not to include incremental policy features as part of our final Model 2. Ultimately, none of these policy variables (length of mask mandates, length and amount of increased government assistance via enhanced unemployment benefits, length business closures, length of stay at home mandates, and length of travel quarantine restrictions) returned a p-value that would allow us to reject the null hypothesis that the model residuals had not measurably improved.

Still, it is worth noting that all of the aforementioned policy features, which were declared to mitigate COVID spread, demonstrated a negative correlation (from approximately -0.5 to -0.2) with our outcome variable of COVID cases per 100k people. The fact that these policy features failed to reject the null hypothesis in the ANOVA F-Test relative to the features already in our Model 2 was not entirely unexpected. Conceptually, several of the features share a significant amount information with median transit mobility change. One could make the argument that business closures, quarantine mandates, and stay at home mandates are all captured, to some extent, in the transit mobility change. 

# Ryan fleshing out writing here

Unemployment insurance extensions and benefit increases

We were surprised, however, that mask mandates 


# Jun's policy tests (all failed) for Model 2 here (to be reviewed...):

```{r base model, echo=FALSE, message=FALSE, results=FALSE}

#model_base=cases_per_100k_at_365d ~ median_transit_change + pop_pct_age_0_24 + population_density 
#summary(lm.I)
#resid(lm.I)
#coeftest(m, vcov. = vcovHC(m, type = 'HC1'))
#shapiro.test(lm.II$residuals)
#bptest(lm.II)
```


```{r pack the plot, echo=FALSE, message=FALSE, results=FALSE}

resid<-function(lm.model)
  {
    qplot(lm.model$residuals,
          geom = "histogram", bins = 20) +
          labs(title = "Histogram of residuals",x = "residual")

    qplot(lm.model$fitted, lm.model$residuals,
            geom = "point") +
          geom_abline(intercept = 0,
                     slope = 0,
                     colour = "red") +
          geom_smooth(aes(x = lm.model$fitted,
                         y = lm.model$residuals),
                         colour = 'blue',
                        method = "loess", se = TRUE) +
         labs(title = "Plot of residuals vs fitted values", x = "fitted value", y = "residual")
}



```

```{r model2 adding mask_mandate_days to base model}

#model_base=cases_per_100k_at_365d ~ median_transit_change + pop_pct_age_0_24 + population_density 
#Model_3=cases_per_100k_at_365d ~ median_transit_change + pop_pct_age_0_24 + population_density + mask_mandate_days+unemployment_benefits_days #+increased_weekly_unemployment_insurance_amt_thru_jul31+business_close_open_days+travel_quarantine_mandate_days+stay_at_home_days

#lm.II=lm(Model_3,data=final_df)
#summary(lm.II)
#resid(lm.II)
#anova(lm.II, lm.I, test = "F")
#shapiro.test(lm.II$residuals)
#bptest(lm.II)
```

<!-- ```{r check models treat policy as indicator variable using a flag} -->

<!-- model_I=cases_per_100k_at_365d ~ median_transit_change + pop_pct_age_0_24 + population_density  -->
<!-- model_II_flag=cases_per_100k_at_365d ~ median_transit_change + pop_pct_age_0_24 + population_density +travel_quarantine_mandate_flag -->
<!-- model_III_flag=cases_per_100k_at_365d ~ median_transit_change + pop_pct_age_0_24 + population_density +stay_at_home_flag -->
<!-- model_IV_flag=cases_per_100k_at_365d ~ median_transit_change + pop_pct_age_0_24 + population_density +mask_mandate_flag -->
<!-- ``` -->

<!-- ```{r adding travel_quarantine_mandate_flag as an indicator variable to base model} -->
<!-- model_II_flag -->
<!-- lm.II_flag=lm(model_II_flag,data=final_df) -->
<!-- summary(lm.II_flag) -->
<!-- resid(lm.II_flag) -->
<!-- shapiro.test(lm.II_flag$residuals) -->
<!-- bptest(lm.II_flag) -->
<!-- coeftest(lm.II_flag, vcov = vcovHC(lm.II_flag, type = "HC0")) -->
<!-- ``` -->

<!-- ```{r adding stay_at_home_flag as an indicator variable to base mode} -->
<!-- model_III_flag -->
<!-- lm.III_flag=lm(model_III_flag,data=final_df) -->
<!-- summary(lm.III_flag) -->
<!-- resid(lm.III_flag) -->
<!-- shapiro.test(lm.III_flag$residuals) -->
<!-- bptest(lm.III_flag) -->
<!-- coeftest(lm.III_flag, vcov = vcovHC(lm.III_flag, type = "HC0")) -->
<!-- ``` -->

<!-- ```{r adding mask_mandate_flag  as an indicator variable to base mode} -->
<!-- model_IV_flag -->
<!-- lm.IV_flag=lm(model_IV_flag,data=final_df) -->
<!-- summary(lm.IV_flag) -->
<!-- resid(lm.IV_flag) -->
<!-- shapiro.test(lm.IV_flag$residuals) -->
<!-- bptest(lm.IV_flag) -->
<!-- ``` -->

```{r}
save.image(file = "pwd/model_2_workspace.RData")
```


