---
title: "Model 2 & 3 clean_script"
author: "Jun Qian, Lucas Schroyer, Ryan Mitchell, Oliver Chang"
date: "4/8/2021"
output: 
  pdf_document: 
    fig_caption: yes
    fig_crop: no
    latex_engine: xelatex
 # html_document: default
header-includes:
   - \usepackage{floatrow}
   - \floatsetup[figure]{capposition=top}
   - \usepackage{caption}
   - \captionsetup[figure]{labelformat=empty}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r load packages, echo=FALSE, warning=FALSE, message=FALSE}
rm(list = ls())
library(dplyr)
library(ggplot2) 
library(purrr)
library(haven)
library(tidyverse)
# install.packages("DescTools")
library(DescTools)
library(magrittr)
library(kableExtra)
require(plotrix)
# install.packages("magick")
# install.packages("webshot")
library("magick")
library("webshot")
# webshot::install_phantomjs()

#install.packages("openxlsx") 
library(openxlsx)
#install.packages("readxl")
library(readxl)
#nstall.packages("rapportools")
library(rapportools)
#install.packages("data.table")
library(data.table)

library(patchwork)
library(sandwich)
library(lmtest)

#install.packages("corrplot")
#install.packages("psych")
library(corrplot)
library(psych)
library(stargazer)
```


# Introduction here
 
As of the writing of the document, the COVID-19 coronavirus (COVID-19) has been spreading throughout the United States for nearly 14-15 months, with the initial cases identified as having entered the country in January 2020. This report uses data from the United States Census Bureau (including state level demographics and county level population and population density data), the New York Times for COVID-19 case counts,  a Google dataset on state-level mobility data, and related COVID-19 policy data from the US State Policy Database. All data used in the project was pulled in on April 10th, 2021.

Our team’s primary research question was “How does mobility impact the spread of COVID-19?” To begin to answer that question, our research team decided to conduct an exploratory observational analysis using OLS regression to measure the complex relationships that exist between changes in a states’ population mobility and state-level COVID-19 case counts per 100K people in the 365 days following each state’s declaration of a state of emergency (SOE). As part of this endeavor, we also explore whether other variables, such as state age demographics, population density, and state level policies on mask mandates, stay at home orders, quarantine restrictions, enhanced unemployment benefits, and business closures might also have an impact on COVID case counts.
This research question was initially motivated as an attempt to understand if the preventive measures that states have enacted in response to the pandemic were associated with statistically significant changes in case counts. Initially, we had hoped to find a causal relationship between mobility and COVID case counts. However, we ultimately decided against this because of the high likelihood of  reverse causality between these variables (i.e. a change in mobility causes a change in case counts which in turn will cause a change in mobility). Additionally, given how complex the nature of pandemics are, there was a strong possibility for omitted variable bias (such as state level differences in temperature and humidity, behavioral differences in terms of mask compliance, COVID testing availability, the percentage and absolute numbers of people using mass transit, and the percentage and absolute numbers of people who are able to work from home, to name a few). These omitted variables will be discussed in the model limitations section of this report.
We decided to focus on COVID cases as our dependent variable, as opposed to COVID deaths, because we inferred that COVID deaths counts are directly dependent on the number of COVID cases and other causal inputs, such as genetic predisposition, underlying health conditions/comorbidities, hospital utilization rates, the availability of various treatment options (ventilators, experimental drugs, etc.). Given COVID cases are a direct input to COVID deaths and much of the data needed to analyze these supplemental variables is not easily available or likely does not exist, a study on COVID death counts may suffer from substantial omitted variable bias. This would raise questions about the interpretation of our model in terms of both statistical and practical significance. 
Our motivation for normalizing the dependent variable per 100K people 365 days after each state’s declaration of a state of emergency was as follows: 

Absolute population counts vary substantially from state to state, and population being the most important factor in absolute COVID case counts is not an interesting finding.
One year was a natural ending point given that we recently passed the one year mark for each state’s declaration of a state of emergency. Additionally, we believe that the mere act of the state declaring an emergency may have contributed to shifts in the behaviors of the residents of each state, so we wanted to index our analysis against that moment in time.
We decided to regress on population mobility as our key variable of interest because: 
Mobility fits well into a causal regression framework for COVID cases, because physical proximity is a requirement for disease transmission, and proximity is a function of mobility (and population density, which we will also explore in our modeling efforts). 
The mobility data captures the actual effects of multiple correlated policies intended to reduce COVID transmission (such as stay-at-home orders, quarantine requirements after traveling or possible exposure to a person who tested positive, business and school closures, etc.). This is effectively a method of dimensionality reduction that contributes to model parsimony.



# Feature Selection for OLS Regression
For this study, we aggregated the different data sources across their individual study horizons (usually more than a year) to generate a small sample of 50 observations. Ultimately, we generated three linear models using OLS regressions of increasing complexity to explore the relations between our data’s features and the case counts. The summary table below and the corresponding descriptions discuss the features we analyzed for our OLS regression descriptive models to understand their association with the dependent variable (i.e. case count per 100,000 people) included: 

| Feature | Present in which model | Source |
|:-----------------|:----|:------|
| Mobility (% change)   | 1, 2, 3  | Google Dataset |
| Population Density (People/sq. mi.) | 1, 2, 3  | US Census Data |
| Percent of Population Living in a High Population Density County (%) | 1, 2, 3  | US Census Data |
| Percent of Population Under the Age of 24 (%)  | 2, 3   | US Policy Database |
| Mask Mandate Days | 2, 3 | US Policy Database |
| Unemployment Benefit Days | 3 | US Policy Database |
| Increased Weekly Unemployment Insurance Amount Through July 31 | 3 | US Policy Database |
| Business Close To Open Days | 3 | US Policy Database |
| Travel Quarantine Mandate Days | 3 | US Policy Database |
| Stay at Home Days | 3 | US Policy Database |

`Case Count Per 100,000 people`: We chose the case count per 100,000 people (refered to as case counts in the rest of this research paper) as our outcome variable. We decided to normalize the case counts around the population as we were concerned that a OLS regression absolute case count would not result in any meaningful association discoveries. For example, the state of California has had some of the highest case counts despite it having some of the most aggressive policies to curb the spread of COVID-19, but this likely is due to the states massive population compared to other states with less aggressive COVID-19 policies.

`Mobility (% Change)`: We decided to regress on population mobility because physical proximity is a requirement for disease transmission and because mobility data captures the actual effects of multiple correlated policies intended to reduce COVID transmission (such as stay-at-home orders, quarantine requirements after traveling or possible exposure to a person who tested positive, business and school closures, etc.). This is effectively a method of dimensionality reduction that contributes to model parsimony. This dataset tracks the changes in mobility for the following sectors: (1) Grocery and Pharmacy, (2) Parks, (3) Residential, (4) Retail and Recreation, (5) Transit Stations, and (6) Workplaces. Ultimately, we decided to use the percent change in transit mobility in our models for two primary reasons (described in detail later). First is that most of these other features are highly correlated with transit. Second is that we couldn’t determine a method for aggregating these features into a statewide change in mobility data as the raw data was captured in percent changes and not absolute changes. We theorized that changes in transit station mobility would be the most associated with changes in case counts from this list as transit stations are often identified as major spreaders of disease.

`Population Density (People/sq. mi.)`: Normalized the state’s population by its area (given in square miles).

`Percent of Population Living in a High Population Density County (%)`: While normalizing a state’s case count by the population is useful, we decided to add an additional feature illustrating what percentage of the population lives in a high density county, which we defined as the top 50 counties in the state when ranked by county population per square mile. An illustrative example of why we added this feature can be seen in the state of New York, which was one of the earliest states to be plagued with the virus. According to the New York Times COVID-19 tracking database, New York City alone has had 882K of New York’s 1.94M (45%) total cases since the beginning of the pandemic (as of April 10th, 2021).

`Percent of Population Under the Age of 24 (%)`: The media and research studies alike have suggested that young adults and children are less likely to be impacted by the virus or may be asymptomatic compared with older adults. As a result, this young age group is more likely to continue spreading COVID-19. We hope to uncover a relationship between a state’s percentage of the population with young people and a corresponding change in case counts.

`Mask Mandate`: the number of days that a state had a mask mandate.

Other model 3 policy features: We selected the following policy-related features from the COVID-19 US State Policy Database (www.tinyurl.com/statepolicies) that we thought related to COVID cases including, the date the state of emergency declared, length of mask mandate, length of stay-at-home orders, length of business closure, length of travel quarantine mandate, length of increased unemployment benefits, and increased unemployment insurance amount. All the policy-related features were recorded as dates, except for the increased unemployment insurance amount that was recorded as integers. Ultimately, what we were interested in was the total days a given policy was active for during the one year period after a state of emergency was announced for each state.

# Initial Data Loading and Cleaning

First, we read in the NYT Covid database from an excel workbook (see the data folder in our repository for all of the raw data files used in this analysis). 

```{r read in NYT covid data, echo=FALSE, warning=FALSE, message=FALSE}


## Pull data from NYT COVID Database and plot summary
NYT_Data <- fread("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-states.csv")
#summary(NYT_Data)

## Convert date strings to dates. 
NYT_Data[,date:=as.Date(date)]
#summary(NYT_Data)

## Calculate cases on a time interval
start.date <- as.Date("2021-01-01")
end.date <- as.Date("2021-02-28")

interval.cases <- NYT_Data %>%
  arrange(state, date) %>% 
#          date == start.date) %>%
  group_by(state) %>%
  mutate(cases_inc = cases - lag(cases),
         deaths_inc = deaths - lag(deaths)) %>%
  ungroup() %>% 
  filter(cases_inc >= 0)

```

Then, we read in the policy data from an excel workbook downloaded from the US State Policy Database.

```{r read in policy data script, echo=FALSE, message=FALSE, warning=FALSE}
tab_names <- excel_sheets(path = "data/US_Covid_Policy_data.xlsx")

list_all <- lapply(tab_names, 
                   function(x) read_excel(path = "data/US_Covid_Policy_data.xlsx", 
                                                     sheet = x))
#Rename list elements
names(list_all) <- tab_names %>% 
    tolower() %>%
    gsub(pattern = "_", replacement = " ") %>% 
    str_to_title() %>%
    gsub(pattern = " ", replacement = ".") 

#Rename colums in the DF
for (df in 1:length(list_all)){
  name_qc <- names(list_all)[df] 
  #print(name_qc)
  if(name_qc %in% c("Stay.At.Home", "Unemployment.Benefits")){
    names(list_all[[df]]) <- list_all[[df]][1,]
    list_all[[df]] <- list_all[[df]][-1,]
  }
  
  names(list_all[[df]]) <- gsub(" ", "_", names(list_all[[df]]) %>% tolower())
}

# names(list_all$Stay.At.Home) <- list_all$Stay.At.Home[1,]
# list_all$Stay.At.Home <- list_all$Stay.At.Home[-1,]


#Join the separate sheets into one master sheet
policy_df_0 <- list_all$State.Characteristics %>%
  select(state, state_abbreviation, state_fips_code,
         population = population_2018,
         area_sq_mi = square_miles,
         population_density = population_density_per_square_mile) %>%
  left_join(list_all$State.Of.Emergency %>%
              select(state, 
                     state_of_emergency_declared = state_of_emergency_issued),
            by = "state") %>%
  left_join(list_all$Masks %>%
              select(state, begin_mask_mandate = public_face_mask_mandate, 
                     end_face_mask_mandate),
            by = "state") %>%
  mutate(begin_mask_mandate = as.Date(begin_mask_mandate, 
                                      origin = "1899-12-30"),
         end_face_mask_mandate = as.Date(end_face_mask_mandate, 
                                         origin = "1899-12-30")) %>%
  mutate(mask_mandate_flag = ifelse(year(begin_mask_mandate) > 2000, 1, 0)) %>%
  left_join(list_all$Stay.At.Home %>%
              select(state,
                     begin_stay_at_home = `stay_at_home/shelter_in_place`,
                     begin_stay_at_home2 = `stay-at-home_order_issued_but_did_not_specifically_restrict_movement_of_the_general_public`,
                     end_stay_at_home = `end_stay_at_home/shelter_in_place`),
            by = "state") %>%
  mutate(begin_stay_at_home = as.numeric(begin_stay_at_home),
         begin_stay_at_home2 = as.numeric(begin_stay_at_home2)) %>%
  mutate(begin_stay_at_home = case_when(
         begin_stay_at_home == 0 & begin_stay_at_home2 == 0 ~ 0,
         begin_stay_at_home == 0  ~ begin_stay_at_home2,
         begin_stay_at_home2 == 0  ~ begin_stay_at_home,
         TRUE ~ ifelse(begin_stay_at_home < begin_stay_at_home2, 
                       begin_stay_at_home, begin_stay_at_home2)
         ),
         begin_stay_at_home = as.Date(as.numeric(begin_stay_at_home), 
                                      origin = "1899-12-30"),
         end_stay_at_home = as.Date(as.numeric(end_stay_at_home), 
                                    origin = "1899-12-30")) %>%
  select(-begin_stay_at_home2) %>%
  mutate(stay_at_home_flag = ifelse(year(begin_stay_at_home) > 2000, 1, 0)) %>%
  left_join(list_all$Business.Closures %>%
              select(state, first_business_closures, first_business_reopening),
            by = "state") %>%
  left_join(list_all$Travel.Quarantines %>%
            select(state, quarantine_mandate_for_some_travelers,
                   quarantine_mandate_for_all_travelers,
                   end_travel_quarantine_mandate = quarantine_mandate_ended),
            by = "state") %>%
  mutate(quarantine_mandate_for_some_travelers = as.Date(
    quarantine_mandate_for_some_travelers, origin = "1899-12-30"),
         quarantine_mandate_for_all_travelers = as.Date(
           quarantine_mandate_for_all_travelers, origin = "1899-12-30")) %>%
  mutate(begin_travel_quarantine_mandate = ifelse(
    quarantine_mandate_for_some_travelers >
                     quarantine_mandate_for_all_travelers,
                     quarantine_mandate_for_some_travelers,
                     quarantine_mandate_for_all_travelers),
begin_travel_quarantine_mandate = as.Date(begin_travel_quarantine_mandate),
end_travel_quarantine_mandate = as.Date(end_travel_quarantine_mandate, 
                                        origin = "1899-12-30")) %>%
  mutate(travel_quarantine_mandate_flag = ifelse(year(
    begin_travel_quarantine_mandate) > 2000, 1, 0)) %>%
  select(-quarantine_mandate_for_some_travelers, 
         -quarantine_mandate_for_all_travelers) %>%
  left_join(list_all$Unemployment.Benefits %>%
            select(state,
               begin_increased_unemployment_benefits = 
                 extended_benefits_program_activated,
               end_increased_unemployment_benefits = 
                 extended_benefits_program_deactivated,
               increased_weekly_unemployment_insurance_amt_thru_jul31 =
"weekly_ui_maximum_amount_with_extra_stimulus_(through_july_31,_2020)_(dollars)"),
            by = "state") %>%
  mutate(begin_increased_unemployment_benefits =
           as.Date(as.numeric(begin_increased_unemployment_benefits),
                   origin = "1899-12-30"),
         end_increased_unemployment_benefits =
           as.Date(as.numeric(end_increased_unemployment_benefits),
                   origin = "1899-12-30"),
         increased_weekly_unemployment_insurance_amt_thru_jul31 =
           as.numeric(increased_weekly_unemployment_insurance_amt_thru_jul31))
  

#saveRDS(policy_df_0, file = "pwd/AggregatedPolicyData.rds")
```

Then, we read in the Google dataset (from an excel workbook) on state-level changes in mobility data. 

```{r load mobility data, echo=FALSE, warning=FALSE, message=FALSE}
US_mobility_data_0 <- read_csv("data/2020_US_Region_Mobility_Report.csv", 
#                              skip = 1, 
                              col_names = TRUE)

names(US_mobility_data_0) <-  names(US_mobility_data_0) %>% 
    tolower() %>%
    str_to_title() %>%
    gsub(pattern = " ", replacement = ".")   

```

Next, we read in three spreadsheets available for download from the U.S. Census Bureau to obtain county-level demographics, including population and area.

```{r load census county population and area data, echo=FALSE, warning=FALSE, message=FALSE}
#Read in Census Data
acs_with_overlays <- read_csv("data/ACSDP1Y2019.DP05_data_with_overlays_2021-03-18T145421.csv", 
                              skip = 1, 
                              col_names = TRUE)

names(acs_with_overlays) <-  names(acs_with_overlays) %>% 
    tolower() %>%
    str_to_title() %>%
    gsub(pattern = " ", replacement = ".") %>%
    gsub(pattern = "!!", replacement = ".") %>%
    gsub(pattern = "!", replacement = ".")  

# Get the area data by state
#https://www2.census.gov/library/publications/2001/compendia/ccdb00/tabB1.pdf
#https://www.census.gov/library/publications/2001/compendia/ccdb00.html
US_population_by_area_0 <- read.xlsx("data/LND01_census_area.xlsx", 
#                              skip = 1, 
                              colNames = TRUE) %>% 
  select(Areaname,	Census_fips_code = STCOU, SqMi = LND110190D)

# Get the population data by state
# https://www.census.gov/data/datasets/time-series/demo/popest/...
# 2010s-counties-total.html#par_textimage_70769902
US_population_by_county_0 <- read_csv("data/co-est2019-alldata.csv", 
#                              skip = 1, 
                              col_names = TRUE) %>% #glimpse()
  # select(COUNTY) %>% unique()
  select(STNAME, CTYNAME, POPESTIMATE2019)

names(US_population_by_county_0) <-  names(US_population_by_county_0) %>% 
    tolower() %>%
    str_to_title()

US_population_by_county <- US_population_by_county_0 %>% 
  group_by(Stname) %>% 
  #there is also a state level entry
  mutate(StatePop = sum(Popestimate2019)/2) %>% 
  ungroup() %>% 
  mutate(CountyPopPerc = Popestimate2019/StatePop) %>% 
  arrange(Stname, desc(CountyPopPerc)) 
          
```

Now that we have read in all of the raw datasets we will use in this study, we joined the mobility data with the county-level population and area data.

```{r join census and mobility data, echo=FALSE, warning=FALSE, message=FALSE, fig.width=4, fig.height=3}
US_mobility_data <- US_mobility_data_0 %>% 
  left_join(US_population_by_area_0, by = "Census_fips_code") %>% 
  select(-Areaname)

# Check to see if the county names match the mobility data county names
US_population_by_county$PresentFlag <- 0
US_population_by_county$Sub_region_2 <- NA

for (i in unique(US_mobility_data$Sub_region_2)){
  US_population_by_county <- US_population_by_county %>% 
    mutate(PresentFlag = if_else(Ctyname %like% i, 1, PresentFlag),
           Sub_region_2 = ifelse(Ctyname %like% i, i, Sub_region_2))
}
US_population_by_county$PresentFlag <- replace_na(
  US_population_by_county$PresentFlag, 0) 

#Join the mobility data, population data, and area data
US_mobility_data2 <- US_mobility_data %>% 
  dplyr::rename(Stname = Sub_region_1) %>%
  left_join(US_population_by_county %>% 
              select(Stname, 
                     Sub_region_2, 
                     CountyPopPerc,
                     CountyPop = Popestimate2019, 
                     StatePop), 
            by = c("Stname","Sub_region_2")) %>% 
  dplyr::rename(Countyname = Sub_region_2) %>%
  filter(Stname != Countyname)

#Check this date has all 50 states. "2020-03-30" is a date where all values
# are present
stopifnot(US_mobility_data2 %>% 
  filter(Date == "2020-03-30") %>% 
  select(Stname) %>% unique() %>% nrow() == 50)

#Add pop dens
US_mobility_data2_highpopdens0 <- US_mobility_data2 %>% 
  mutate(county_pop_dens = CountyPop/SqMi)

ggplot(US_mobility_data2_highpopdens0 %>% 
         filter(Date == "2020-03-30"), 
       aes(county_pop_dens)) +
  geom_histogram(bins = 100)

# ggplot(US_mobility_data2_highpopdens0 %>%
#         filter(Date == "2020-03-30"),
#       aes(log10(county_pop_dens))) +
#  geom_histogram(bins = 100)

#print new line
cat(" \n \n")

#User input
pop_dens_filter <- 2000

ggplot(US_mobility_data2_highpopdens0 %>%
        filter(Date == "2020-03-30", county_pop_dens < pop_dens_filter),
      aes(county_pop_dens)) +
 geom_histogram(bins = 100)

#print new line
cat(" \n \n")


#Flag for areas greater than the pop_dens_filter people per sqmi cuttoff
US_mobility_data2_highpopdens <- US_mobility_data2_highpopdens0 %>% 
    mutate(high_popdens_county_flag = ifelse(county_pop_dens > pop_dens_filter, 
                                             1, 0))


US_mobility_data2_county_perc_reallocated <- US_mobility_data2_highpopdens %>% 
  filter(Date == "2020-03-30") %>%
  select(Stname, Countyname, CountyPopPerc, high_popdens_county_flag, 
         StatePop, CountyPop) %>% 
  group_by(Stname) %>% 
  mutate(TotalStatePopAccountedFor = sum(CountyPopPerc, na.rm = T),
         CountyPopPerc_Reallocated = CountyPopPerc/TotalStatePopAccountedFor, 
         high_popdens_flag = max(high_popdens_county_flag, na.rm = T)) %>% 
  ungroup()


#QC that all reallocated perc weights totals to 100 
stopifnot(US_mobility_data2_county_perc_reallocated %>% 
  group_by(Stname) %>%
  summarise(PercSum = sum(CountyPopPerc_Reallocated)) %>% # View()
  filter(PercSum < 1.01 & PercSum > .99) %>% 
  nrow() == (US_mobility_data2_highpopdens$Stname %>% 
               unique() %>% length())) # Check no high pop states were dropped 

US_mobility_data2_perc_pop_highdens <- US_mobility_data2_county_perc_reallocated %>% 
  filter(high_popdens_county_flag == 1) %>% 
  group_by(Stname) %>% 
  summarise(high_popdens_pop_perc = sum(CountyPop, na.rm = T)/StatePop) %>% 
  ungroup() %>% 
  distinct(.keep_all = T) %>% 
  filter(!is.na(high_popdens_pop_perc))

#Join new percents and high pop density percents
US_mobility_data3 <- US_mobility_data2_highpopdens %>% 
  left_join(US_mobility_data2_county_perc_reallocated, 
            by = c("Stname", "Countyname")) %>% 
  left_join(US_mobility_data2_perc_pop_highdens, 
            by = "Stname")
```
From the histograms above, we observe that the population densities are heavily skewed towards the left of the distribution. We then applied a filter to show what the distribution would resemble if we filter out the top 50 counties (which we define as the high population density counties). We then determine what percentage of a state’s population lives in a high population county, with the majority of states having zero percent (i.e. the top 50 counties are found in only 19 states). 

With the county level population observations and mobility observations, we then calculated the weighted average change in mobility at the state level.

Next, we join the state-level mobility observations with the added population and percentage of population in a high density area features to the NYT Covid database by state and date.


```{r join mobility-census data with COVID data, echo=FALSE, message=FALSE, warning=FALSE}
#reset names
US_mobility_data <- US_mobility_data3
rm(US_mobility_data2, US_mobility_data3, US_population_by_county_0, 
   US_mobility_data2_highpopdens, US_mobility_data2_highpopdens0,
   US_population_by_county, US_population_by_area_0, US_mobility_data_0,
   US_mobility_data2_perc_pop_highdens,
   US_mobility_data2_county_perc_reallocated, list_all, NYT_Data)

#join mobility data with covid database

US_mobility_data_agg <- US_mobility_data %>% 
  dplyr::rename("state" = "Stname",
         "date" = "Date") %>%
  group_by(state, date, high_popdens_pop_perc) %>% 
  mutate(Retail_and_recreation_percent_change_from_baseline_weighted = 
           Retail_and_recreation_percent_change_from_baseline * 
           CountyPopPerc_Reallocated,
         Grocery_and_pharmacy_percent_change_from_baseline_weighted = 
           Grocery_and_pharmacy_percent_change_from_baseline * 
           CountyPopPerc_Reallocated,
         Parks_percent_change_from_baseline_weighted = 
           Parks_percent_change_from_baseline * CountyPopPerc_Reallocated,
         Transit_stations_percent_change_from_baseline_weighted =
           Transit_stations_percent_change_from_baseline * 
           CountyPopPerc_Reallocated,
         Workplaces_percent_change_from_baseline_weighted = 
           Workplaces_percent_change_from_baseline * CountyPopPerc_Reallocated,
         Residential_percent_change_from_baseline_weighted = 
           Residential_percent_change_from_baseline * 
           CountyPopPerc_Reallocated) %>% 
  summarize(Retail_and_recreation_percent_change_from_baseline_weighted = 
              sum(Retail_and_recreation_percent_change_from_baseline_weighted, 
                  na.rm = T),
            Grocery_and_pharmacy_percent_change_from_baseline_weighted = 
              sum(Grocery_and_pharmacy_percent_change_from_baseline_weighted, 
                  na.rm = T),
            Parks_percent_change_from_baseline_weighted = 
              sum(Parks_percent_change_from_baseline_weighted, 
                  na.rm = T),
            Transit_stations_percent_change_from_baseline_weighted = 
              sum(Transit_stations_percent_change_from_baseline_weighted, 
                  na.rm = T), 
            Workplaces_percent_change_from_baseline_weighted = 
              sum(Workplaces_percent_change_from_baseline_weighted, 
                  na.rm = T),
            Residential_percent_change_from_baseline_weighted = 
              sum(Residential_percent_change_from_baseline_weighted, 
                  na.rm = T)) %>% 
  ungroup()

US_cases_and_mobility <- US_mobility_data_agg %>% 
  left_join(interval.cases, by = c("state", "date"))

#QC the join
stopifnot(US_cases_and_mobility %>% nrow()
  == US_mobility_data_agg %>% nrow())

```


# Exploratory Data Analysis

For our analysis, we aggregated the year-plus worth of COVID-19 data into a single metric per state for a total data frame size of 50 observations. We decided to aggregate one-years worth of observations after a state declared a state of emergency, which we are using as a proxy to indicate the “start date” of a state’s serious attempts to curb the spread of the virus. We ultimately decided upon one year’s worth of observations to aggregate rather than a shorter time period as we wanted to capture a significant amount of observations for which the temporal impacts would be lessoned. For example, we initially aggregated the first 90 days worth of observations after the state of emergency, however this approach actually resulted in an inverse linear relationship (i.e. negative $\beta$ coefficient in our base model) between change in mobility and change in case counts when we expected a positive relationship. We concluded that 90 days was an insufficient time horizon for most states to determine the appropriate relationship between mobility and case count as the immediate time period following a state of emergency might still see an increase in case counts for a few weeks given the time-dependence of case counts with the previous case counts.

Next, we inspected the correlation between the different measures of mobility changes, we chose to use the state-level median change in transit mobility in the 365 days after each state declared an emergency as our main variable of interest for model 1.


```{r data wrangling and final df, echo=FALSE, message=FALSE, warning=FALSE, fig.width=4, fig.height=3}
#For each state, read in the first 365 days of transit change data, beginning 
# at the date the state declared an emergency 
first_365 <- US_cases_and_mobility %>% 
  left_join(policy_df_0, by = c("state")) %>%
  filter(as.Date(date) >= as.Date(state_of_emergency_declared) & 
           as.Date(date) <= as.Date(state_of_emergency_declared) + 364)
  

#Calculate the median county-population-weigthed value of transit changes for 
# each state in the first 365 days after emergency declaration
transit_chg <- aggregate(
  first_365$Transit_stations_percent_change_from_baseline_weighted, 
  by=list(state=first_365$state), FUN=median)  %>%
  dplyr::rename(transit = x)

retail_chg <- aggregate(
  first_365$Retail_and_recreation_percent_change_from_baseline_weighted,
  by=list(state=first_365$state), FUN=median) %>%
  dplyr::rename(retail = x)

residential_chg <- aggregate(
  first_365$Residential_percent_change_from_baseline_weighted,
  by=list(state=first_365$state), FUN=median) %>%
  dplyr::rename(residential = x)

grocery_chg <- aggregate(
  first_365$Grocery_and_pharmacy_percent_change_from_baseline_weighted,
  by=list(state=first_365$state), FUN=median) %>%
  dplyr::rename(grocery = x)

parks_chg <- aggregate(first_365$Parks_percent_change_from_baseline_weighted, 
                       by=list(state=first_365$state), FUN=median)  %>%
  dplyr::rename(parks = x)

workplace_chg <- aggregate(
  first_365$Workplaces_percent_change_from_baseline_weighted, 
  by=list(state=first_365$state), FUN=median)  %>%
  dplyr::rename(workplace = x)

z <- data.frame(transit_chg$transit, retail_chg$retail, 
                grocery_chg$grocery, parks_chg$parks, workplace_chg$workplace, 
                residential_chg$residential) %>%
  dplyr::rename(Transit = transit_chg.transit, 
                Retail = retail_chg.retail, 
                Grocery = grocery_chg.grocery,
                Parks = parks_chg.parks, 
                Workplace = workplace_chg.workplace, 
                Residential = residential_chg.residential)

#Visualize the correlation between mobility changes
M <- cor(z)
mat1 <- data.matrix(M)

cat("Correlation Matrix: Median Mobility Changes by Category")
print(round(M,2))

# #print new line
# cat(" \n \n \n \n")
# 
# number.cex=0.75
# corrplot(mat1, method = "color", tl.col = 'black', 
#          is.corr=FALSE, cex.var = 0.7, cex.col=0.7, digits = 1,
#          title = 'Correlation Matrix: Median Mobility Changes by Category', 
#          addCoefasPercent = TRUE,  addCoef.col = "white")

#Very high correlations between the mobility changes, except for Parks. We 
#will first explore whether parks mobility change demonstrates a clear 
#relationship with COVID cases, and then explore whether transit mobility 
#shows a linear relationship with cases.

#Calculate the median county-population-weighted value of transit changes 
#for each state in the first 365 days after emergency declaration
mobility_chg <- aggregate(
  first_365$Transit_stations_percent_change_from_baseline_weighted, 
  by=list(state=first_365$state), FUN=median) %>%
  dplyr::rename(median_transit_change = x)


#Calculate the cumulative cases at 365 days post emergency declaration by state  
cases_at_365 <- aggregate(first_365$cases, 
                          by=list(state=first_365$state), FUN=max) %>%
  dplyr::rename(cum_cases_at_365d = x)

#Grab the % of population living in high density variable
high_dens <- aggregate(first_365$high_popdens_pop_perc, 
                       by=list(state=first_365$state), FUN=mean) %>%
  dplyr::rename(high_popdens_pop_perc = x)

#Replace NaN with 0
high_dens$high_popdens_pop_perc[is.nan(high_dens$high_popdens_pop_perc)]<-0

#Create our final dataframe!
final_df <- cases_at_365 %>%
  left_join(policy_df_0, by = c("state")) %>%
  left_join(parks_chg, by = c("state")) %>%
  left_join(mobility_chg, by = c("state")) %>%
  left_join(high_dens, by = c("state")) %>%
  mutate(cases_per_100k_at_365d = 100000*cum_cases_at_365d/population) %>%
  left_join(acs_with_overlays, by = c("state" = "Geographic.Area.Name"))

#print new line
cat(" \n \n \n \n")

#Relationship between median parks mobility change and cumulative case count 
#per 100k at 365 days post statement of emergency
ggplot(data = final_df) +
  geom_point(aes(x = parks,
                 y = cases_per_100k_at_365d)) +
  geom_smooth(aes(x = parks,
                 y = cases_per_100k_at_365d),
            colour = 'red',
            method = 'lm', se = FALSE) +
  geom_smooth(aes(x = parks,
                  y = cases_per_100k_at_365d),
            colour = 'blue',
            method = 'loess', se = TRUE) +
  labs(title = 'Median Parks Mobility Change vs.
Cases Per 100K People For One Year After SOE',
       x='State-Level Median Daily Relative %\nParks Mobility Change',
       y='Cases Per 100K People\nOne Year After SOE') +
  theme(axis.text=element_text(size=8),
        axis.title=element_text(size=8),
        plot.title = element_text(size = 10))


#print new line
cat(" \n \n \n \n")

# Relationship between median transit change and cumulative case count per 100k 
# at 365 days post statement of emergency
ggplot(data = final_df) +
  geom_point(aes(x = median_transit_change,
                 y = cases_per_100k_at_365d)) +
  geom_smooth(aes(x = median_transit_change,
                 y = cases_per_100k_at_365d),
            colour = 'red',
            method = 'lm', se = FALSE) +
  geom_smooth(aes(x = median_transit_change,
                  y = cases_per_100k_at_365d),
            colour = 'blue',
            method = 'loess', se = TRUE) +
  labs(title = 'Median Transit Mobility Change vs.
Cases Per 100K People For One Year After SOE',
       x='State-Level Median Daily Relative %\nTransit Mobility Change',
       y='Cases Per 100K People\nOne Year After SOE') +
  theme(axis.text=element_text(size=8),
        axis.title=element_text(size=8),
        plot.title = element_text(size = 10))

#print new line
cat(" \n \n")

# Assess whether to use mean or median change in transit: We chose median 
# because there is some skew in the data
# h <- hist(first_365$Transit_stations_percent_change_from_baseline_weighted, 
#      main = 
#      paste("Histogram of Relative Daily Changes in Transit Mobility for US States:
#                   First Year"),  
#      xlab='Relative % Change From Baseline Mobility', 
#      ylab='Frequency (Days)', 
#      col='gray') 

h <- ggplot(first_365, aes(Transit_stations_percent_change_from_baseline_weighted)) +
  geom_histogram() +
  xlab('Relative % Change From Baseline Mobility') +
  ylab('Frequency (Days)') +
  ggtitle('Histogram of Relative Daily Changes in
Transit Mobility for US States: First Year')

#h$density = h$density = h$counts/sum(h$counts)
#plot(h, freq = FALSE, col='gray', main = paste("Histogram of Relative Daily Changes in Transit Mobility for US States:
#                  First Year"), xlab='Relative % Change From Baseline Mobility', ylab='Frequency (Days)')


# Simple regression model on the relationship between change in parks mobility 
# and COVID cases per 100K people. 
model_p <- lm(cases_per_100k_at_365d ~ parks, data = final_df)

#Pull out the p-values for the simple regression coefficients
#summary(model_p)$coefficients[,4]
```

```{r data wrangling part 2: additional policy data wrangling, echo=FALSE, message=FALSE}
# Capture # of Days After State of Emergency that a particular 
#policy was in place--------------------

# days of mask mandate --------------------
m1 <- select(final_df, begin_mask_mandate, end_face_mask_mandate, 
             state_of_emergency_declared, cases_per_100k_at_365d) %>%
  mutate(state_of_emergency_declared = as.Date(state_of_emergency_declared))
# str(m1)
m1 <- m1 %>%
  mutate(diff_in_days = case_when(
      begin_mask_mandate == "1899-12-30" ~ 0,
      end_face_mask_mandate == "1899-12-30" &
      begin_mask_mandate != "1899-12-30" ~
        as.numeric(state_of_emergency_declared) -
      as.numeric(begin_mask_mandate) + 364,
    TRUE ~ as.numeric(end_face_mask_mandate) -
      as.numeric(begin_mask_mandate)
  ))

m1$diff_in_days[m1$diff_in_days > 365] <- 365
final_df$mask_mandate_days = m1$diff_in_days


m1 <- select(final_df, 
             begin_increased_unemployment_benefits, 
             end_increased_unemployment_benefits, 
             state_of_emergency_declared, 
             cases_per_100k_at_365d) %>%
  mutate(state_of_emergency_declared = as.Date(state_of_emergency_declared))
# str(m1)
m1 <- m1 %>%
  mutate(diff_in_days = case_when(
      begin_increased_unemployment_benefits == "1899-12-30" ~ 0,
    end_increased_unemployment_benefits == "1899-12-30" &
      begin_increased_unemployment_benefits != "1899-12-30" ~
        as.numeric(state_of_emergency_declared) -
      as.numeric(begin_increased_unemployment_benefits) + 364,
    TRUE ~ as.numeric(end_increased_unemployment_benefits) -
      as.numeric(begin_increased_unemployment_benefits)
  ))

m1$diff_in_days[m1$diff_in_days > 365] <- 365
final_df$unemployment_benefits_days = m1$diff_in_days



# days of stay at home mandate  --------------------
m1 <- select(final_df, 
             begin_stay_at_home, 
             end_stay_at_home, 
             state_of_emergency_declared, 
             cases_per_100k_at_365d) %>%
  mutate(state_of_emergency_declared = as.Date(state_of_emergency_declared))
# str(m1)
m1 <- m1 %>%
  mutate(diff_in_days = case_when(
      begin_stay_at_home == "1899-12-30" ~ 0,
      end_stay_at_home == "1899-12-30" &
      begin_stay_at_home != "1899-12-30" ~
        as.numeric(state_of_emergency_declared) -
      as.numeric(begin_stay_at_home) + 364,
    TRUE ~ as.numeric(end_stay_at_home) -
      as.numeric(begin_stay_at_home)
  ))

m1$diff_in_days[m1$diff_in_days > 365] <- 365
final_df$stay_at_home_days = m1$diff_in_days



# days of travel quarantine mandate  --------------------
m1 <- select(final_df, begin_travel_quarantine_mandate, 
             end_travel_quarantine_mandate, state_of_emergency_declared, 
             cases_per_100k_at_365d) %>%
  mutate(state_of_emergency_declared = as.Date(state_of_emergency_declared))
# str(m1)
m1 <- m1 %>%
  mutate(diff_in_days = case_when(
      begin_travel_quarantine_mandate == "1899-12-30" ~ 0,
      end_travel_quarantine_mandate == "1899-12-30" &
      begin_travel_quarantine_mandate != "1899-12-30" ~
        as.numeric(state_of_emergency_declared) -
      as.numeric(begin_travel_quarantine_mandate) + 364,
    TRUE ~ as.numeric(end_travel_quarantine_mandate) -
      as.numeric(begin_travel_quarantine_mandate)
  ))

m1$diff_in_days[m1$diff_in_days > 365] <- 365
final_df$travel_quarantine_mandate_days = m1$diff_in_days



# days of business closures (first wave)  --------------------

m1 <- select(final_df, first_business_closures,
             first_business_reopening, state_of_emergency_declared, 
             cases_per_100k_at_365d) %>%
  mutate(state_of_emergency_declared = as.Date(state_of_emergency_declared),
         first_business_closures = as.Date(first_business_closures),
         first_business_reopening = as.Date(first_business_reopening)
         )
# str(m1)
m1 <- m1 %>%
  mutate(diff_in_days = case_when(
      first_business_closures == "1899-12-30" ~ 0,
      first_business_reopening == "1899-12-30" &
      first_business_closures != "1899-12-30" ~
        as.numeric(state_of_emergency_declared) -
      as.numeric(first_business_closures) + 364,
    TRUE ~ as.numeric(first_business_reopening) -
      as.numeric(first_business_closures)
  ))

# m1$diff_in_days[m1$diff_in_days > 365] <- 365
final_df$business_closed_days_round1 = m1$diff_in_days
```

After inspection of the correlation matrix between the different measures of mobility changes, we chose to use the state-level median change in transit mobility in the 365 days after each state declared an emergency as our main variable of interest for Model 1. Our motivation for choosing transit over the other mobility features was as follows:

1) Transit is most closely aligned with our understanding of how viruses spread, particularly from one locality or population center to another. 

2) The mobility changes in Transit, Retail, Grocery, and Workplace are highly positively correlated with each other (>0.8 in each pair), and highly negatively correlated with Residential mobility changes (absolute value of >0.7 or above). Highly correlated features should be avoided in descriptive and explanatory linear regression modeling as they tend to increase the standard error estimates on the model parameter estimates for the correlated features. 

The only mobility metric that was not strongly correlated with the others was Parks. Since the median change in Park mobility was not strongly correlated with any other mobility changes, we examined its relationship with our target variable but did not observe a positive or negative linear relationship. A t-Test on our calculated simple regression coefficient failed to reject the null hypothesis that there was no evidence that the coefficient for change in median Parks mobility was measurably different than zero. 

3) We did not want to take an aggregation of the set of highly correlated features (Transit, Retail, Grocery, and Workplace) because the raw data provided are relative numbers and we do not have access to the underlying absolute mobility data, so we would be unable to derive a correct weighted average of these features.

4) Given that the distribution of relative transit mobility change had a left skew, our team decided to use the median value for each state within the 365 day window as a better measure of central tenancy. 

# Base Model

```{r model 1, echo=FALSE, message=FALSE,fig.width=4, fig.height=3}
model_1_final <- lm(cases_per_100k_at_365d ~ median_transit_change, data = final_df)

cat("\n-------Model results-------\n")
summary(model_1_final)
cat(" \n \n \n")

#-------Model Residual Plot-------
# qplot(model_1_final$residuals,
#                geom = "histogram", bins = 20) +
#          labs(title = "Histogram of Model 1 Residuals",
#               x = "Residual") +
#   theme(axis.text=element_text(size=8),
#         axis.title=element_text(size=8),
#         plot.title = element_text(size = 10))

m<-mean(model_1_final$residuals)
std<-sqrt(var(model_1_final$residuals))
hist(model_1_final$residuals, freq=F, breaks=12, xlab='Model 1 residuals',
     main="Histogram of Model 1 Residuals vs Normal Dist.")
curve(dnorm(x , mean = m, sd = std ),col="red", lwd=2, add=TRUE, yaxt="n")


#print new line
cat(" \n \n")

qplot(model_1_final$fitted, model_1_final$residuals,
            geom = "point") +
         geom_abline(intercept = 0,
                     slope = 0,
                     colour = "red") + 
         geom_smooth(aes(x = model_1_final$fitted,
                         y = model_1_final$residuals),
            colour = 'blue',
            method = "loess", se = TRUE) +
         labs(title = "Plot of Residuals vs Fitted Values",
              x = "Fitted Values",
              y = "Residual") +
  theme(axis.text=element_text(size=8),
        axis.title=element_text(size=8),
        plot.title = element_text(size = 10))


cat("\n-------Homoskedasticity Test-------\n")
lmtest::bptest(model_1_final)
cat(" \n")


cat("\n------Normality of Residuals Test-------\n")
shapiro.test(model_1_final$residuals)
cat(" \n")
```

# Model 1 Discussion Here:




# Second Model. 

As we thought about an approach to building our Model 2 specifications, the general approach that our group decided to take was to incrementally test the addition of new features to our Model 1 specification in descending order of expected importance, according to our general understanding of how viruses spread. At each iteration, we began by examining the relationship (using scatterplots) between a new demographic or policy-related feature and our outcome of interest: COVID cases per 100K people 365 days after each state declared a state of emergency. If we observed a relationship, we ran a combination of t-Tests and/or ANOVA F-Tests to determine whether or not to add the feature to our Model 1 specification. We proceeded in this 'greedy' algorithmic fashion by adding variables to our Model 1 specification until we could no longer justify further additions based on results from ANOVA F-Tests. The first incremental feature we tested was derived from observational data from the census bureau on population age distributions by state. 

One of the contributing factors to the spread of COVID-19 is asymptomatic spread. Younger people have been shown to have milder symptoms and therefore it stands to reason that they may be less likely to get tested, and ultimately end up spreading the disease at a greater rate than older age groups. To make matters worse, younger people tend to interact with more people (source?) as a result of being in school (switching between classrooms, touching desks and other surfaces where other students have been, congregating in large cafeterias, etc.), which increases the probability of viral transmission. Hence, for our second model, we were interested in testing our general hypothesis that age demographics may play a role in the spread of COVID-19. We began by doing some basic exploratory data analysis (EDA) with respect to age distributions and cumulative COVID-19 case counts per 100K, which is our target variable for Lab 2.

```{r age EDA less than 24, echo=FALSE, message=FALSE, fig.width= 6, fig.height=3.5}
census_df<-final_df[c('cases_per_100k_at_365d', 
                      'Percent.Sex.And.Age.Total.Population.Under.5.Years', 
                      'Percent.Sex.And.Age.Total.Population.5.To.9.Years', 
                      'Percent.Sex.And.Age.Total.Population.10.To.14.Years', 
                      'Percent.Sex.And.Age.Total.Population.15.To.19.Years',
                      'Percent.Sex.And.Age.Total.Population.20.To.24.Years')]

names(census_df) <- names(census_df) %>% 
  gsub(pattern = "Percent.Sex.And.Age.Total.Population.", 
       replacement = "Pct. ") %>%  
  gsub(pattern = ".To.", replacement = "- \n") %>%  
  gsub(pattern = ".Years", replacement = " Yrs") %>%  
  gsub(pattern = 'cases_per_100k_at_365d', 
       replacement = " Cases per \n 100k")

panel.hist <- function(x, ...)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(usr[1:2], 0, 1.5) )
    h <- hist(x, plot = FALSE)
    breaks <- h$breaks; nB <- length(breaks)
    y <- h$counts; y <- y/max(y)
    rect(breaks[-nB], 0, breaks[-1], y, col = "cyan", ...)
}

panel.cor<-function(x,y)
  {
    usr<-par("usr"); on.exit(par(usr))
    par(usr=c(0,1,0,1))
    r=round(cor(x,y),digits=2)
    text(0.5,0.5,r)
  }

# census_df %>% names()
pairs(census_df,lower.panel = panel.cor,
      upper.panel = panel.smooth, 
      diag.panel = panel.hist, 
      cex.labels=1, 
      gap = 0.5,
      labels = c("Cases", "Age <5%", "Age 5-9%", "Age 10-14%", 
                 "Age 15-19%", "Age 20-24%"),
      main = "Case vs Age Bins Distribution and Scatter Plots")

```


```{r age EDA 25-59, echo=FALSE, message=FALSE, fig.width= 6, fig.height=3.5}
census_df<-final_df[c('cases_per_100k_at_365d', 
                      'Percent.Sex.And.Age.Total.Population.25.To.34.Years',
                      'Percent.Sex.And.Age.Total.Population.35.To.44.Years',
                      'Percent.Sex.And.Age.Total.Population.45.To.54.Years',
                      'Percent.Sex.And.Age.Total.Population.55.To.59.Years')]

names(census_df) <- names(census_df) %>% 
  gsub(pattern = "Percent.Sex.And.Age.Total.Population.", 
       replacement = "Pct. ") %>%  
  gsub(pattern = ".To.", replacement = "- \n") %>%  
  gsub(pattern = ".Years", replacement = " Yrs") %>%
  gsub(pattern = 'cases_per_100k_at_365d', replacement = " Cases per \n 100k")

panel.cor<-function(x,y)
  {
    usr<-par("usr"); on.exit(par(usr))
    par(usr=c(0,1,0,1))
    r=round(cor(x,y),digits=2)
    text(0.5,0.5,r)
  }

# census_df %>% names()
pairs(census_df,lower.panel = panel.cor,
      upper.panel = panel.smooth, 
      diag.panel = panel.hist, cex.labels=1, gap = 0.5,
      labels = c("Cases", "Age 25-34%", "Age 35-44%", 
                 "Age 45-54%", "Age 55-59%"),
      main = "Case vs Age (Contin.) Bins Distribution and Scatter Plots")

```

```{r age EDA 60+, echo=FALSE, message=FALSE, fig.width= 6, fig.height=3.5}
census_df<-final_df[c('cases_per_100k_at_365d',
                      'Percent.Sex.And.Age.Total.Population.60.To.64.Years',
                      'Percent.Sex.And.Age.Total.Population.65.To.74.Years',
                      'Percent.Sex.And.Age.Total.Population.75.To.84.Years',
                      'Percent.Sex.And.Age.Total.Population.85.Years.And.Over')]

names(census_df) <- names(census_df) %>% 
  gsub(pattern = "Percent.Sex.And.Age.Total.Population.", 
       replacement = "Pct. ") %>%  
  gsub(pattern = ".To.", replacement = "- \n") %>%  
  gsub(pattern = ".Years", replacement = " Yrs") %>%  
  gsub(pattern = 'cases_per_100k_at_365d', replacement = " Cases per \n 100k")

panel.cor<-function(x,y)
  {
    usr<-par("usr"); on.exit(par(usr))
    par(usr=c(0,1,0,1))
    r=round(cor(x,y),digits=2)
    text(0.5,0.5,r)
  }
#print new line
# cat(" \n ")
pairs(census_df,
      lower.panel = panel.cor, upper.panel = panel.smooth, 
      diag.panel = panel.hist, cex.labels=1, gap = 0.5,
      labels = c("Cases", "Age 60-64%", "Age 65-74%", 
                 "Age 75-86%", "Age 85+ %"),
      main = "Case vs Age (Contin.) Bins Distribution and Scatter Plots")
```


```{r age demo F-tests for feature creation, echo=FALSE, message=FALSE}

# Build nested models for categorical age demographic data where 
# visual inspection suggested interesting relationships with target
model_a = lm(cases_per_100k_at_365d ~ median_transit_change + Percent.Sex.And.Age.Total.Population.Under.5.Years, data = final_df)

model_b = lm(cases_per_100k_at_365d ~ median_transit_change +
               Percent.Sex.And.Age.Total.Population.Under.5.Years +
               Percent.Sex.And.Age.Total.Population.5.To.9.Years, 
             data = final_df)

model_c = lm(cases_per_100k_at_365d ~ median_transit_change +
               Percent.Sex.And.Age.Total.Population.Under.5.Years +
               Percent.Sex.And.Age.Total.Population.5.To.9.Years +
               Percent.Sex.And.Age.Total.Population.10.To.14.Years, 
             data = final_df)

model_d = lm(cases_per_100k_at_365d ~ median_transit_change +
               Percent.Sex.And.Age.Total.Population.Under.5.Years +
               Percent.Sex.And.Age.Total.Population.5.To.9.Years +
               Percent.Sex.And.Age.Total.Population.10.To.14.Years +
               Percent.Sex.And.Age.Total.Population.15.To.19.Years, 
             data = final_df)

model_e = lm(cases_per_100k_at_365d ~ median_transit_change +
               Percent.Sex.And.Age.Total.Population.Under.5.Years +
               Percent.Sex.And.Age.Total.Population.5.To.9.Years +
               Percent.Sex.And.Age.Total.Population.10.To.14.Years +
               Percent.Sex.And.Age.Total.Population.15.To.19.Years +
               Percent.Sex.And.Age.Total.Population.20.To.24.Years, 
             data = final_df)
```

```{r wrap-hook, echo=FALSE}
library(knitr)
hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = knitr:::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})
```

```{r, linewidth=60}
#Significant 
anova(model_a, model_1_final, test = "F")

#Insignificant 
anova(model_b, model_a, test = "F")

#Significant F-test
anova(model_c, model_a, test = "F")

#Insignificant relative to model_c
anova(model_d, model_c, test = "F")
anova(model_e, model_d, test = "F")
anova(model_e, model_c, test = "F")
```

When performing EDA on the categorical age group distributions and their relationship to our target variable, we noticed a strong positive correlation to the target among age groups 0-24. Age groups in the 24+ range did not appear to follow a consistent pattern with respect to correlation with our target variable and were therefore not a key focus area for our analysis.

Next, we performed a series of ANOVA F-tests on a nested set of linear regression models with parameter estimates for this set of age groups (Under 5, 5-9, 10-14, 15-19, and 20-24) as well as our main variable of interest (median transit mobility change). Our motivation here was to understand whether the regression residuals were measurably different from one another between the different (nested) model specifications. For context, the null hypothesis for an F-test is that fitting additional coefficients for a longer model does not measurably reduce the residuals relative to a nested model with fewer parameters. 

Our first ANOVA F-test compared our Model 1 with a new model that had an additional parameter estimate for the percentage of the population under 5 years old. With a p-value of 0.0003, we rejected the null hypothesis and used this new model (model_a) as the baseline model for subsequent comparisons with additional parameter estimates for different age categories. 

We failed to reject the null hypothesis when adding an estimator for ages 5-9 (model_b), and succeeded in rejecting the null hypothesis when adding an estimator for ages 10-14 (model_c), with a p-value of 0.001. Adding additional estimators for 15-19 and 20-24 failed to reject the null hypothesis that these models (model_d and model_e) were measurably better at reducing residuals than model_c. These results suggested creating two new features for the percentage of the population ages 0-9 and 10-24 and adding them to our base Model 1 to create the first specification for our Model 2.

```{r df update 1, echo=TRUE, message=FALSE} 
final_df <- final_df %>% 
  mutate(pop_pct_age_0_9 = Percent.Sex.And.Age.Total.Population.Under.5.Years + 
           Percent.Sex.And.Age.Total.Population.5.To.9.Years,
                    pop_pct_age_10_24 = 
           Percent.Sex.And.Age.Total.Population.10.To.14.Years +
           Percent.Sex.And.Age.Total.Population.15.To.19.Years +
           Percent.Sex.And.Age.Total.Population.20.To.24.Years)

cor(final_df$pop_pct_age_0_9, final_df$pop_pct_age_10_24)

final_df <- final_df %>% 
  mutate(pop_pct_age_0_24 = Percent.Sex.And.Age.Total.Population.Under.5.Years + 
           Percent.Sex.And.Age.Total.Population.5.To.9.Years +
           Percent.Sex.And.Age.Total.Population.10.To.14.Years +
           Percent.Sex.And.Age.Total.Population.15.To.19.Years +
           Percent.Sex.And.Age.Total.Population.20.To.24.Years)
```

However, after measuring a 0.77 correlation between these two features - and with the goal of increased model parsimony - we decided to group them together to prevent the standard errors for their respective coefficients from increasing substantially. Let's take a look and assess whether this new variable for percentage of the population < 24 years old visually satisfies the conditional linearity expectation with respect to our target.

```{r incremental variables 1, echo=FALSE, message=FALSE, fig.width = 4, fig.height=3, fig.align="center"}
#print new line
cat(" \n ")
ggplot(data = final_df) +
  geom_point(aes(x = pop_pct_age_0_24,
                 y = cases_per_100k_at_365d)) +
  geom_smooth(aes(x = pop_pct_age_0_24,
                 y = cases_per_100k_at_365d),
            colour = 'red',
            method = 'lm', se = FALSE) +
  geom_smooth(aes(x = pop_pct_age_0_24,
                  y = cases_per_100k_at_365d),
            colour = 'blue',
            method = 'loess', se = TRUE) +
  labs(title = 
         'Perc. of State Pop. Under Age 25 vs.
Cases Per 100K People',
       x='Percentage of State Population Under Age 25',
       y='Cases Per 100K People\nOne Year After SOE') +
  theme(axis.text=element_text(size=8),
        axis.title=element_text(size=8))
#print new line
cat(" \n ")
```

The conditional linear expectation between our population percentage aged 0-24 and our target appears to be met. In addition to evaluating the linear relationships between the demographic age variables and our target, we also evaluated the log, square root, and square transformations to the age distribution data but did not find them to aid in reducing the frequency or magnitude of outlier data points. 

Indeed, including a feature for the percentage of the population aged < 24 years old appears to have improved our model's performance. An ANOVA F-test returned a p-value of 0.0001, suggesting that we reject the null hypothesis that the (interim) Model 2's residuals were not measurably different from the residuals of Model 1.

```{r model 2 - part 1, echo=FALSE, message=FALSE}
model_2a <- lm(cases_per_100k_at_365d ~ median_transit_change + 
                 pop_pct_age_0_24, data = final_df)
# Significant
anova(model_2a, model_1_final, test = "F")
```

After accounting for changes in mobility and demographic age differences between states, the next variable we wanted to explore as part of our descriptive model for COVID case counts was population density. According to the World Health Organization, "COVID-19 virus is primarily transmitted between people through respiratory droplets and contact routes." (https://www.who.int/news-room/commentaries/detail/modes-of-transmission-of-virus-causing-covid-19-implications-for-ipc-precaution-recommendations). In other words, COVID spreads primarily through physical interactions between infected and uninfected hosts, regardless of whether the actual mechanism of transmission is airborne or surface based contact. Hence, it stands to reason that more densely populated areas would see greater rates of infections, because the frequency of these physical interactions will increase with population density. This was the motivation for our group exploring whether a relationship existed between state population density and our outcome variable of interest.


```{r incremental variables 2, echo=FALSE, message=FALSE, fig.width = 4, fig.height=3, fig.align="center"}
#print new line
cat(" \n ")
ggplot(data = final_df) +
  geom_point(aes(x = population_density,
                 y = cases_per_100k_at_365d)) +
  geom_smooth(aes(x = population_density,
                 y = cases_per_100k_at_365d),
            colour = 'red',
            method = 'lm', se = FALSE) +
  geom_smooth(aes(x = population_density,
                  y = cases_per_100k_at_365d),
            colour = 'blue',
            method = 'loess', se = TRUE) +
  labs(title = 'Pop. Density vs.
Cases Per 100K People',
       x='Population Density (people/sq. mi)',
       y='Cases Per 100K People One Year After SOE') +
  theme(axis.text=element_text(size=8),
        axis.title=element_text(size=9))
#print new line
cat(" \n ")
```

To our surprise, however, there was no clear relationship between population density and our outcome variable. A t-Test on the parameter estimate for population density's relationship with our target variable failed to reject the null hypothesis that the coefficient value was not measurably different from zero. 

```{r simple population density model, echo=FALSE, message=FALSE}
model_density <- lm(cases_per_100k_at_365d ~ population_density , 
                    data = final_df)
summary(model_density)
```

In spite of this test, our group decided to move forward and try including the population density feature in Model 2, as we believed it to be a conceptually meaningful variable in describing the population prevalence of COVID in each state one year after each state declared a state of emergency. Therefore, we proceeded with an ANOVA F-Test to test whether the incremental population density feature measurably improved model performance (via reduction of residuals) relative to our current model with features for median transit mobility change and percentage of the population < 24 years old. This ANOVA F-test returned a p-value of 0.002, enough to reject the null hypothesis that the model residuals were not measurably different from one another.


```{r model 2 - part 2, echo=FALSE, message=FALSE, fig.width = 4, fig.height=3, fig.align="center"}
model_2_final <- lm(cases_per_100k_at_365d ~ median_transit_change + pop_pct_age_0_24 + population_density, data = final_df)

cat("\n-------Model results-------\n")
summary(model_2_final)
cat("\n")

# Significance Test Relative To Model 1
cat("\n-------ANOVA F-Test Significance Test Relative To Model 1-------\n")
anova(model_2_final, model_1_final, test = "F")
cat("\n")

# Significance Test Relative To Interim Model 2
cat("\n-------ANOVA F-Test Significance Test Relative To Interim Model 2-------\n")
anova(model_2_final, model_2a, test = "F")
cat("\n")

#-------Model Residual Plot-------
qplot(model_2_final$residuals,
               geom = "histogram", bins = 20) +
         labs(title = "Histogram of Model 2 Residuals",
              x = "residual")

qplot(model_2_final$fitted, model_2_final$residuals,
            geom = "point") +
         geom_abline(intercept = 0,
                     slope = 0,
                     colour = "red") + 
         geom_smooth(aes(x = model_2_final$fitted,
                         y = model_2_final$residuals),
            colour = 'blue',
            method = "loess", se = TRUE) +
         labs(title = "Plot of Residuals vs Fitted Values",
              x = "fitted value",
              y = "residual")


cat("\n-------Homoskedasticity Test-------\n")
lmtest::bptest(model_2_final)
cat("\n")


cat("\n------Normality of Residuals Test-------\n")
shapiro.test(model_2_final$residuals)
cat("\n")
```

Because the population density feature only becomes statistically significant at the p = 0.05 level in our model when we include features for median change in transit mobility and the percentage of the population under age 25, we say that the population density has a conditional relationship with our outcome of interest. Both of these two co-variates (median transit mobility change and percentage of the population under age 25) are negatively correlated with population density and positively correlated with our outcome variable. 

```{r conditional effect population density, echo=FALSE, message=FALSE, fig.width = 4, fig.height=3, fig.align="center"}
#print new line
cat(" \n ")
ggplot(data = final_df) +
  geom_point(aes(y = population_density,
                 x = median_transit_change)) +
  geom_smooth(aes(y = population_density,
                 x = median_transit_change),
            colour = 'red',
            method = 'lm', se = FALSE) +
  geom_smooth(aes(y = population_density,
                  x = median_transit_change),
            colour = 'blue',
            method = 'loess', se = TRUE) +
  labs(title = 'Population Density vs. \nMedian Transit Mobility Change',
       y='State Population Density (people/sq. mi)',
       x='State-Level One Year Median Transit Mobility Change') +
  theme(axis.text=element_text(size=8),
        axis.title=element_text(size=8))

#print new line
cat(" \n ")

ggplot(data = final_df) +
  geom_point(aes(y = population_density,
                 x = pop_pct_age_0_24)) +
  geom_smooth(aes(y = population_density,
                 x = pop_pct_age_0_24),
            colour = 'red',
            method = 'lm', se = FALSE) +
  geom_smooth(aes(y = population_density,
                  x = pop_pct_age_0_24),
            colour = 'blue',
            method = 'loess', se = TRUE) +
  labs(title = 'Population Density vs. \nPercent of Population Under Age 25',
       y='State Population Density (people/sq. mi)',
       x='Percentage of the State Population Under Age 25') +
  theme(axis.text=element_text(size=8),
        axis.title=element_text(size=8))

```

However, we are only interested in the unique variation of population density with respect to our outcome variable. When the OLS regression algorithm calculates the parameter estimate for population density, it starts by regressing population density on the other model co-variate (input) features. The residuals from that regression represent the portion of population density that is *not* colinear with median transit mobility change and percentage of the population under age 25. Then OLS regresses our target values on those residuals to derive an estimate for the population density parameter. The model summary tells us that if we hold the percentage of the population under 25 and the median transit mobility change for a state constant (we do not allow them to co-vary), that there exists a positive correlation between population density and our outcome variable at a statistically significant level (p = 0.002) using classical standard errors.

At this stage, we wanted to explore whether any state policy changes aimed at reducing the spread of COVID-19 added incremental descriptive power beyond our current Model 2 specification. In particular, we wanted to examine whether the timing of mask mandates, length and amount of increased government assistance via enhanced unemployment benefits, business closures, stay at home mandates, and travel quarantine restrictions had measurable effects on our outcome of interest after accounting for the features already in our Model 2 specification (which included state-level features for median change in transit mobility, percentage of the population under 25 years of age, and population density). All the policy-related features were recorded as dates, except for the increased unemployment insurance amount, which was recorded as an integer. 

To align with our target variable of COVID-19 Cases per 100K one year after state of emergency declaration, we encoded the date related policy variables as the total number of days each policy was in place for after the state of emergency was announced for each state (up to 365 days). For transparency:

1. If a policy had no beginning and end dates, the total days were assigned as zero.
2. If a policy had beginning but not end dates, the total days were calculated by the date of state emergency declared + 364 days - the date of the beginning of the policy.
3. If a policy had both beginning and end dates, the total days were calculated by the difference in days of the two dates.

Once the policy-related features of our interest were transformed into days in force, we conducted EDA on the policy-features and COVID cases per 100k population using scatter plot and correlation matrices. 



```{r policy days vs cases per capita, echo=FALSE, message=FALSE, fig.width= 6, fig.height=3.5}

# Plot first half of policy vars
m1 <- select(final_df, cases_per_100k_at_365d, 
             mask_mandate_days,
             unemployment_benefits_days,
             increased_weekly_unemployment_insurance_amt_thru_jul31
            )

panel.cor<-function(x,y)
  {
    usr<-par("usr"); on.exit(par(usr))
    par(usr=c(0,1,0,1))
    r=round(cor(x,y),digits=2)
    text(0.5,0.5,r)
}

#print new line
cat(" \n \n")
# m1 %>% names()
pairs(m1,
      cex.labels=1, gap = 0.5,
      lower.panel = panel.cor,
      upper.panel = panel.smooth,
      diag.panel = panel.hist,
      labels = c("Cases", "Mask Mandate Days","Unemp. Benef. Days", 
                 "Incr. Unempl. Insur."),
      main = "Policy Days vs Cases Per Capita Distribution and Scatter Plots")


# Plot second half of policy vars
m2 <- select(final_df, cases_per_100k_at_365d, 
             business_closed_days_round1,
             travel_quarantine_mandate_days,
             stay_at_home_days
            )

panel.cor<-function(x,y)
  {
    usr<-par("usr"); on.exit(par(usr))
    par(usr=c(0,1,0,1))
    r=round(cor(x,y),digits=2)
    text(0.5,0.5,r)
}

#print new line
cat(" \n ")
# m2 %>% names()
pairs(m2,
      lower.panel = panel.cor, upper.panel = panel.smooth, 
      diag.panel = panel.hist, cex.labels=1, gap = 0.5,
      labels = c("cases", "businesss\nclosed days", 
                 "travel\nquarantine", "stay at\nhome"),
      main = 
        "Policy Days (Contin.) vs Cases Per Cap. Distrib. and Scatter Plots")

```



```{r policy correlation plot, echo=FALSE, message=FALSE}
z <- data.frame(final_df$cases_per_100k_at_365d, 
             final_df$mask_mandate_days,
             final_df$unemployment_benefits_days,
             final_df$increased_weekly_unemployment_insurance_amt_thru_jul31,
             final_df$business_closed_days_round1,
             final_df$travel_quarantine_mandate_days,
             final_df$stay_at_home_days) %>%
  dplyr::rename(cases_per_100k = final_df.cases_per_100k_at_365d, 
             mask_days = final_df.mask_mandate_days,
             ue_ben_days = final_df.unemployment_benefits_days,
             ue_ins_amt = 
               final_df.increased_weekly_unemployment_insurance_amt_thru_jul31,
             biz_closed_days = final_df.business_closed_days_round1,
             quarantine_days = final_df.travel_quarantine_mandate_days,
             stay_at_home_days = final_df.stay_at_home_days)

#Visualize the correlation between state policies and cases
M <- cor(z)
mat1 <- data.matrix(M)
# print(M)
# cat("\nCorrelation Matrix: State Policies vs. Cases")
```

```{r fig.cap = "Correlation Matrix: State Policies vs. Cases", echo=FALSE, message=FALSE, warning=FALSE, fig.width=8, fig.height=6, out.width="90%"}
corrplot(mat1, method = "color", 
         tl.col = 'black', is.corr=FALSE, 
         # title = 'Correlation Matrix: State Policies vs. Cases',
         addCoefasPercent = TRUE,  addCoef.col = "white", 
         tl.cex = 1, tl.srt = 15,
         type = "lower", #order = "hclust",
         cl.ratio = 0.6, 
         cl.align = "c")
cat(" \n \n")
```

From the scatterplots, we see varying degrees of linearity between the policy features and our outcome of interest. We tested each of these features iteratively in the same manner as before, using significance from ANOVA F-tests as the benchmark to decide whether or not to include incremental policy features as part of our final Model 2. Ultimately, none of these policy variables (length of mask mandates, length and amount of increased government assistance via enhanced unemployment benefits, length business closures, length of stay at home mandates, and length of travel quarantine restrictions) returned a p-value that would allow us to reject the null hypothesis that the model residuals had not measurably improved.

Still, it is worth noting that all of the aforementioned policy features, which were declared to mitigate COVID spread, demonstrated a negative correlation (from approximately -0.5 to -0.2) with our outcome variable of COVID cases per 100k people. The fact that these policy features failed to reject the null hypothesis in the ANOVA F-Test relative to the features already in our Model 2 was not entirely unexpected. Conceptually, several of the features share a significant amount information with median transit mobility change. One could make the argument that business closures, quarantine mandates, and stay at home mandates are all captured, to some extent, in the transit mobility change. 

# Ryan fleshing out writing here

Unemployment insurance extensions and benefit increases

We were surprised, however, that mask mandates 


# Jun's policy tests (all failed) for Model 2 here (to be reviewed...):

```{r model 2 additional policy variables ANOVA F-Tests}
#Testing mask mandate days: Failed F-Test
model_2_final_incremental_test1 <- lm(cases_per_100k_at_365d ~ 
                                        median_transit_change + 
                                        pop_pct_age_0_24 + population_density + 
                                        mask_mandate_days, data = final_df)
anova(model_2_final_incremental_test1, model_2_final, test = "F")

#Testing extended unemployment benefit days: Failed F-Test
model_2_final_incremental_test2 <- lm(cases_per_100k_at_365d ~ 
                                        median_transit_change + 
                                        pop_pct_age_0_24 + population_density + 
                                        unemployment_benefits_days, 
                                      data = final_df)
anova(model_2_final_incremental_test2, model_2_final, test = "F")

#Testing increased unemployment insurance amount: Failed F-Test
model_2_final_incremental_test3 <- lm(cases_per_100k_at_365d ~ 
                                        median_transit_change + 
                                        pop_pct_age_0_24 + population_density + increased_weekly_unemployment_insurance_amt_thru_jul31, data = final_df)
anova(model_2_final_incremental_test3, model_2_final, test = "F")

#Testing mask mandate days: Failed F-Test
model_2_final_incremental_test4 <- lm(cases_per_100k_at_365d ~ 
                                        median_transit_change + 
                                        pop_pct_age_0_24 + population_density + 
                                        business_closed_days_round1, 
                                      data = final_df)
anova(model_2_final_incremental_test4, model_2_final, test = "F")

#Testing quarantine mandate days: Failed F-Test
model_2_final_incremental_test5 <- lm(cases_per_100k_at_365d ~ 
                                        median_transit_change + 
                                        pop_pct_age_0_24 + population_density + travel_quarantine_mandate_days, data = final_df)
anova(model_2_final_incremental_test5, model_2_final, test = "F")

#Testing stay at home mandate days: Failed F-Test
model_2_final_incremental_test6 <- lm(cases_per_100k_at_365d ~ 
                                        median_transit_change + 
                                        pop_pct_age_0_24 + population_density + 
                                        stay_at_home_days, data = final_df)
anova(model_2_final_incremental_test6, model_2_final, test = "F")
```


```{r pack the plot, echo=FALSE, message=FALSE, results=FALSE}

resid<-function(lm.model)
  {
    qplot(lm.model$residuals,
          geom = "histogram", bins = 20) +
          labs(title = "Histogram of residuals",x = "residual")

    qplot(lm.model$fitted, lm.model$residuals,
            geom = "point") +
          geom_abline(intercept = 0,
                     slope = 0,
                     colour = "red") +
          geom_smooth(aes(x = lm.model$fitted,
                         y = lm.model$residuals),
                         colour = 'blue',
                        method = "loess", se = TRUE) +
         labs(title = "Plot of residuals vs fitted values", 
              x = "fitted value", y = "residual")
}

```

```{r model2 adding mask_mandate_days to base model}

#model_base=cases_per_100k_at_365d ~ median_transit_change + 
#pop_pct_age_0_24 + population_density 
#Model_3=cases_per_100k_at_365d ~ median_transit_change + 
#pop_pct_age_0_24 + population_density + mask_mandate_days+
#unemployment_benefits_days 
#+increased_weekly_unemployment_insurance_amt_thru_jul31+
#business_close_open_days+travel_quarantine_mandate_days+stay_at_home_days

#lm.II=lm(Model_3,data=final_df)
#summary(lm.II)
#resid(lm.II)
#anova(lm.II, lm.I, test = "F")
#shapiro.test(lm.II$residuals)
#bptest(lm.II)
```

<!-- ```{r check models treat policy as indicator variable using a flag} -->

<!-- model_I=cases_per_100k_at_365d ~ median_transit_change + pop_pct_age_0_24 + population_density  -->
<!-- model_II_flag=cases_per_100k_at_365d ~ median_transit_change + pop_pct_age_0_24 + population_density +travel_quarantine_mandate_flag -->
<!-- model_III_flag=cases_per_100k_at_365d ~ median_transit_change + pop_pct_age_0_24 + population_density +stay_at_home_flag -->
<!-- model_IV_flag=cases_per_100k_at_365d ~ median_transit_change + pop_pct_age_0_24 + population_density +mask_mandate_flag -->
<!-- ``` -->

<!-- ```{r adding travel_quarantine_mandate_flag as an indicator variable to base model} -->
<!-- model_II_flag -->
<!-- lm.II_flag=lm(model_II_flag,data=final_df) -->
<!-- summary(lm.II_flag) -->
<!-- resid(lm.II_flag) -->
<!-- shapiro.test(lm.II_flag$residuals) -->
<!-- bptest(lm.II_flag) -->
<!-- coeftest(lm.II_flag, vcov = vcovHC(lm.II_flag, type = "HC0")) -->
<!-- ``` -->

<!-- ```{r adding stay_at_home_flag as an indicator variable to base mode} -->
<!-- model_III_flag -->
<!-- lm.III_flag=lm(model_III_flag,data=final_df) -->
<!-- summary(lm.III_flag) -->
<!-- resid(lm.III_flag) -->
<!-- shapiro.test(lm.III_flag$residuals) -->
<!-- bptest(lm.III_flag) -->
<!-- coeftest(lm.III_flag, vcov = vcovHC(lm.III_flag, type = "HC0")) -->
<!-- ``` -->

<!-- ```{r adding mask_mandate_flag  as an indicator variable to base mode} -->
<!-- model_IV_flag -->
<!-- summary(lm.IV_flag) -->
<!-- resid(lm.IV_flag) -->
<!-- shapiro.test(lm.IV_flag$residuals) -->
<!-- bptest(lm.IV_flag) -->
<!-- ``` -->


# Third Model

<!-- $$  -->
<!-- \text{ Model  3}:\ -->
<!--   cases_per_100k_at_365d}=\beta_0 + \beta_1 \text{median_transit_change} + \\ -->
<!--   \beta_2 \text{pop_pct_age_0_24} + \beta_3 \text{population_density} + \\ -->
<!--   \beta_4 \text{mask_mandate_days} + \beta_5 \text{unemployment_benefits_days} + \\ -->
<!--   \beta_6 \text{increased_weekly_unemployment_insurance_amt_thru_jul3} + \\ -->
<!--   \beta_7 \text{business_close_open_days} + \beta_8 \text{travel_quarantine_mandate_days} + \\ -->
<!--   \beta_9 \text{stay_at_home_days} + \epsilon -->
<!-- $$ -->

### Model 3:

<!-- \begin{equation} -->
<!-- \text{cases_per_100k_at_365d} &= \beta_0 + \beta_1 \text{median_transit_change} \\ -->
<!--   &+ \beta_2 \text{pop_pct_age_0_24} + \beta_3 \text{population_density} \\ -->
<!--   &+ \beta_4 \text{mask_mandate_days} + \beta_5 \text{unemployment_benefits_days}\\ -->
<!--   &+ \beta_6 \text{increased_weekly_unemployment_insurance_amt_thru_jul3}\\ -->
<!--   &+ \beta_7 \text{business_close_open_days} + \beta_8 \text{travel_quarantine_mandate_days}\\ -->
<!--   &+ \beta_9 \text{stay_at_home_days} + \epsilon -->
<!-- \end{equation} -->


```{r model 3, echo=FALSE, fig.width = 4, fig.height=3, fig.align="center"}
model_3_final <- lm(cases_per_100k_at_365d ~ median_transit_change +
                      pop_pct_age_0_24 + population_density +
                      mask_mandate_days + unemployment_benefits_days + 
                      increased_weekly_unemployment_insurance_amt_thru_jul31 + 
                      business_closed_days_round1 + 
                      travel_quarantine_mandate_days + stay_at_home_days, 
                    data = final_df)

summary(model_3_final)

# NOT Significant
anova(model_3_final, model_2_final, test = "F")


# Visually Evaluate Model 2b
qplot(model_3_final$residuals,
               geom = "histogram", bins = 20) +
         labs(title = "Histogram of residuals",
              x = "residual")

qplot(model_3_final$fitted, model_3_final$residuals,
            geom = "point") +
         geom_abline(intercept = 0,
                     slope = 0,
                     colour = "red") + 
         geom_smooth(aes(x = model_3_final$fitted,
                         y = model_3_final$residuals),
            colour = 'blue',
            method = "loess", se = TRUE) +
         labs(title = "Plot of residuals vs fitted values",
              x = "fitted value",
              y = "residual")

```


# Regression Table

```{r regression table}
robust_se_1 <- coeftest(model_1_final,
                        vcovHC(model_1_final, type = 'HC3'))[ , "Std. Error"]

robust_se_2 <- coeftest(model_2_final,
                        vcovHC(model_2_final, type = 'HC3'))[ , "Std. Error"]

robust_se_3 <- coeftest(model_3_final,
                        vcovHC(model_3_final, type = 'HC3'))[ , "Std. Error"]
```

```{r stargazer, echo=FALSE}
# Print results
# stargazer(model_1_final, model_2_final, model_3_final,
#           type = "text",
#           se = list(robust_se_1, robust_se_2, robust_se_3),
#           title = "Table 1: OLS models for COVID-19 Spread",
#           column.sep.width = "0.5pt",
#           align=TRUE, 
#           header = FALSE,
#           font.size = "small",
#           single.row = TRUE,
#           out = "pwd/fit_lm.txt") # to put coefficients and standard errors on same line


# jp
# stargazer(model_1_final, model_2_final, model_3_final,
#           type = 'text',
#           title = "Table 1: OLS models for COVID-19 Spread",
#           # float.env = "sidewaystable",
#           covariate.labels=c("median_transit_change",
#                              "pop_pct_age_0_24", 
#                              "population_density",
#                              "mask_mandate_days",
#                              "unemployment_benefits",
#                              "increased_weekly_unemp",
#                              "business_closed_days",
#                              "travel_quarantine_man",
#                              "stay_at_home_days"),
#           # rownames = FALSE, 
#           se = list(robust_se_1, robust_se_2, robust_se_3)
#           # font.size=6,
#           # header=FALSE, # to get rid of r package output text
#           # single.row = TRUE, # to put coefficients and standard errors on same line
#           # no.space = TRUE, # to remove the spaces after each line of coefficients
#           # column.sep.width = "1pt", # to reduce column width
#           # font.size = "small" # to make font size smaller
# 
# )

```

![stargazer output](pwd/fit_lm.png)


# Plots, Figures, and Tables 

Do the plots, figures and tables that the team has chosen to include successfully move forward the argument that they are making? Has the team chosen the most effective method (a table or a chart) to display their evidence? Is that table or chart the most communicative it could be? Is every plot, figure, and table that is included in the report referenced in the narrative argument?

# Assessment of the CLM. 

Has the team presented a sober assessment of the CLM assumptions that might be problematic for their model? Have they presented their analysis about the consequences of these problems (including random sampling) for the models they estimate? Did they use visual tools or statistical tests, as appropriate? Did they respond appropriately to any violations?

# An Omitted Variables Discussion. 

Did the report miss any important sources of omitted variable bias? Are the estimated directions of bias correct? Was their explanation clear? Is the discussion connected to whether the key effects are real or whether they may be solely an artifact of omitted variable bias?

# Conclusion. 

Does the conclusion address the research question? Does it raise interesting points beyond numerical estimates? Does it place relevant context around the results?

Are there any other errors, faulty logic, unclear or unpersuasive writing, or other elements that leave you less convinced by the conclusions?

# General Notes:

"In principle the SE reflects the degree of uncertainty or the lack of information for getting a 'good' ( that is reliable) estimate of a parameter. Therefore if you keep everything else the same ( eg the same variation in the response, the same number of observations) but you increase the number of separate parameters to be estimated there will be less information per parameter to get the estimate, and hence larger standard error. Precisely what happens will depend on the the degree of variation in the additional X variable that is included and how colinear it is with already included variables."

Known IID violations:
Geo-spatial dependence (states near each other are not independent...physical proximity)
Policy coordination dependence (states near each-other have coordinated policies (like NY/NJ quarantine policies, etc))

Other limitations: 
Mobility data is based on Google-Maps cell phone users. Not everyone has access to a smart phone or uses Google Maps and allows their location to be traced, so this data may not be representative of the population. Additionally, we do not have absolute numbers, only relative change data. 
